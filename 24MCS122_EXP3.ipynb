{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMicFsPgYTPNVxUFJW/46i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uknat/DL-Lab/blob/main/24MCS122_EXP3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 3: Optimization and Regularization\n",
        "\n",
        "Abstract\n",
        "\n",
        "In this experiment, we investigate optimization and regularization techniques for training a neural network to recognize handwritten digits using the USPS dataset. The network features a 256-unit input layer, one hidden layer with logistic (sigmoid) activation, dropout for regularization, and a 10-way softmax output layer. We explore efficient optimization via gradient descent with momentum and examine various regularization strategies—including dropout and L2 weight decay—to enhance generalization. Additionally, we experiment with the number of hidden units and employ early stopping. All experimental runs are logged and visualized using Weights & Biases (wandb) to facilitate a data–driven hyperparameter search. Our results indicate that a carefully tuned hidden layer size, moderate weight decay, and early stopping lead to improved classification performance on the USPS dataset.\n",
        "\n",
        "1. Introduction\n",
        "\n",
        "Handwritten digit recognition is a classic problem in machine learning, with applications ranging from postal code recognition to bank check processing. In this experiment, we focus on the USPS dataset, which provides grayscale images of handwritten digits. The dataset is split into three parts:\n",
        "\n",
        "Training Data: 1,000 samples\n",
        "Validation Data: 1,000 samples\n",
        "Test Data: The remaining approximately 9,000 samples\n",
        "Each image is represented by a 256-dimensional vector (each element corresponding to one pixel), and the goal is to classify the digit (0–9) represented by the image.\n",
        "\n",
        "Our neural network model consists of:\n",
        "\n",
        "An input layer of 256 units.\n",
        "One hidden layer with logistic (sigmoid) activation functions.\n",
        "Dropout is applied after the hidden layer as a regularization technique.\n",
        "A 10-unit output layer that produces logits for a 10-way softmax classification.\n",
        "The loss function is cross-entropy loss, and we use Stochastic Gradient Descent (SGD) with momentum as the optimizer. We systematically investigate:\n",
        "\n",
        "A baseline configuration with no weight decay.\n",
        "The effect of different L2 weight decay coefficients on generalization.\n",
        "The effect of varying the number of hidden units (model parameters) on validation performance.\n",
        "The benefits of early stopping combined with an optimal hidden layer size.\n",
        "2. Weights & Biases (wandb) Integration\n",
        "\n",
        "Weights & Biases (wandb) is a powerful tool for experiment tracking, visualization, and collaboration. In this experiment, wandb is used to log metrics (e.g., training/validation loss and accuracy) for every run, compare different hyperparameter settings, and visualize run history. Key wandb functionalities include:\n",
        "\n",
        "Run Initialization and Login:\n",
        "Before starting any experiment, you create an account on wandb.ai and log in from Colab using wandb.login(). This associates your experiments with your wandb dashboard.\n",
        "Experiment Logging:\n",
        "As the training proceeds, metrics such as loss and accuracy are logged via wandb.log(). These metrics appear in real time on the wandb dashboard, enabling you to monitor performance across epochs.\n",
        "Run Summary and History:\n",
        "At the end of each experiment, a run summary (including epoch count, final training/validation loss, and accuracy) is automatically generated and stored on your wandb dashboard.\n",
        "Team/Entity Setup:\n",
        "Depending on your account type (personal or team), you may need to specify an entity when initializing wandb. For instance, if your project is under a team, use the team’s entity name."
      ],
      "metadata": {
        "id": "CSK_pkBMPwbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU"
      ],
      "metadata": {
        "id": "7Cnavj-0QvhO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "NZX5ApwfPcGI",
        "outputId": "43917a4d-3a33-471b-d0a1-772fa79ea6a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabhinav21black\u001b[0m (\u001b[33mabhinav21black-national-institute-of-technology-hamirpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login --relogin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkG2ju2gRM6j",
        "outputId": "929407c6-cef4-44fe-f3ce-cdf7ecac4ccd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Define a run identifier (you can increment this as needed)\n",
        "run = 1\n",
        "\n",
        "wandb.init(\n",
        "    project=\"usps-digit-classification\",\n",
        "    name=f\"experiment_{run}\",\n",
        "    config={\n",
        "        \"hidden_units\": 128,  # Default hidden units; you can override in each experiment\n",
        "        \"dropout_rate\": 0.5,\n",
        "        \"learning_rate\": 0.40,\n",
        "        \"momentum\": 0.9,\n",
        "        \"num_epochs\": 100,\n",
        "        \"batch_size\": 100,\n",
        "        \"dataset\": \"USPS\",\n",
        "        \"architecture\": \"SimpleNN with one logistic hidden layer and dropout\",\n",
        "        \"optimizer\": \"SGD with momentum\"\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "h1C_-YeJQAsy",
        "outputId": "47273caa-acdd-49cb-e42a-61cb292e5bab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/z06u9y4b?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x796eb9bf0410>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Data Loading and Preprocessing\n",
        "\n",
        "The USPS dataset is stored in an HDF5 file on Google Drive. In the next cell, we mount the drive, load the dataset, normalize the images, shuffle the data, and split it into 1,000 training samples, 1,000 validation samples, and the remaining test samples.\n",
        "\n",
        "Data Source: USPS dataset from Kaggle.\n",
        "\n",
        "Preprocessing:\n",
        "\n",
        "The images (256-dimensional vectors) are normalized to the [0, 1] range.\n",
        "\n",
        "Splitting:\n",
        "\n",
        "The dataset is partitioned into:\n",
        "\n",
        "1,000 samples for training,\n",
        "\n",
        "1,000 samples for validation,\n",
        "\n",
        "Approximately 9,000 samples for testing.\n"
      ],
      "metadata": {
        "id": "RCtEsGwTQZjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvegsFxVSiCG",
        "outputId": "a96c7647-045f-41df-e218-f2a410c7be6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to your HDF5 file.\n",
        "path = \"/content/drive/MyDrive/DL lab/usps.h5\"\n",
        "\n",
        "# Open the HDF5 file and load the data.\n",
        "with h5py.File(path, 'r') as hf:\n",
        "    train_group = hf.get('train')\n",
        "    X_tr_full = train_group.get('data')[:]     # e.g., shape: (7291, 256)\n",
        "    y_tr_full = train_group.get('target')[:]     # e.g., shape: (7291,)\n",
        "\n",
        "    test_group = hf.get('test')\n",
        "    X_te = test_group.get('data')[:]             # e.g., shape: (2007, 256)\n",
        "    y_te = test_group.get('target')[:]           # e.g., shape: (2007,)\n",
        "\n",
        "print(\"Train data shape:\", X_tr_full.shape)\n",
        "print(\"Train target shape:\", y_tr_full.shape)\n",
        "print(\"Test data shape:\", X_te.shape)\n",
        "print(\"Test target shape:\", y_te.shape)\n",
        "\n",
        "# Convert to float32 and normalize if necessary.\n",
        "X_tr_full = X_tr_full.astype(np.float32)\n",
        "X_te = X_te.astype(np.float32)\n",
        "if X_tr_full.max() > 1.0:\n",
        "    X_tr_full /= 255.0\n",
        "if X_te.max() > 1.0:\n",
        "    X_te /= 255.0\n",
        "\n",
        "# Shuffle the training data.\n",
        "np.random.seed(42)\n",
        "indices = np.random.permutation(len(X_tr_full))\n",
        "X_tr_full = X_tr_full[indices]\n",
        "y_tr_full = y_tr_full[indices]\n",
        "\n",
        "# Split training data: first 1,000 for training, next 1,000 for validation.\n",
        "X_train = X_tr_full[:1000]\n",
        "y_train = y_tr_full[:1000]\n",
        "X_val   = X_tr_full[1000:2000]\n",
        "y_val   = y_tr_full[1000:2000]\n",
        "\n",
        "# For testing, use the provided test split.\n",
        "X_test = X_te\n",
        "y_test = y_te\n",
        "\n",
        "print(f\"Final split shapes:\\n X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HQs6jA-TGks",
        "outputId": "50c25896-c5c3-4ed0-82f0-7450af3e7198"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (7291, 256)\n",
            "Train target shape: (7291,)\n",
            "Test data shape: (2007, 256)\n",
            "Test target shape: (2007,)\n",
            "Final split shapes:\n",
            " X_train: (1000, 256), X_val: (1000, 256), X_test: (2007, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class USPSDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Create dataset objects for train, validation, and test.\n",
        "train_dataset = USPSDataset(X_train, y_train)\n",
        "val_dataset   = USPSDataset(X_val, y_val)\n",
        "test_dataset  = USPSDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "mT7oHGdlTJGE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Model Definition\n",
        "\n",
        "We define a simple neural network with:\n",
        "\n",
        "Input layer: 256 units (one per pixel).\n",
        "Hidden layer: A single hidden layer with logistic (sigmoid) activation. The number of units is tunable.\n",
        "Regularization: Dropout is applied after the hidden layer.\n",
        "Output layer: 10 units corresponding to the 10 digits (0–9).\n",
        "The cross–entropy loss function is used, which internally applies a softmax on the output logits."
      ],
      "metadata": {
        "id": "rZuXRxGiTLZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, hidden_units=128, dropout_rate=0.5):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(256, hidden_units)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden_units, 10)  # 10 outputs for digits 0-9\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.sigmoid(x)  # Logistic activation\n",
        "        x = self.dropout(x)   # Dropout for regularization\n",
        "        x = self.fc2(x)       # Output logits (CrossEntropyLoss applies softmax internally)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "YU7t1dp9TN3v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Training and Evaluation Functions\n",
        "\n",
        "We define helper functions to perform one epoch of training and evaluation. These functions compute the cross–entropy loss and classification accuracy."
      ],
      "metadata": {
        "id": "8OFiskx1TQem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use GPU if available.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training for one epoch.\n",
        "def train_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "# Evaluation (validation or test)\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return total_loss / total, correct / total"
      ],
      "metadata": {
        "id": "sXzIfwteTS2W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Experiment Helper Function\n",
        "\n",
        "The run_experiment(config) function encapsulates the training process for a given hyperparameter configuration. It creates data loaders, instantiates the model, sets up the optimizer (with optional weight decay), and trains the model while logging metrics to wandb. Early stopping is applied if a \"patience\" value is provided."
      ],
      "metadata": {
        "id": "1phvo2h4TT7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def run_experiment(config):\n",
        "    \"\"\"\n",
        "    Runs training with the specified configuration.\n",
        "    config keys:\n",
        "      - hidden_units (int)\n",
        "      - weight_decay (float)\n",
        "      - learning_rate (float)\n",
        "      - momentum (float)\n",
        "      - num_epochs (int)\n",
        "      - batch_size (int)\n",
        "      - dropout_rate (optional, float)\n",
        "      - patience (optional, int): early stopping patience.\n",
        "    \"\"\"\n",
        "    # Create new DataLoaders.\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "    # Use dropout_rate from config if provided; otherwise default to 0.5.\n",
        "    dropout_rate = config.get('dropout_rate', 0.5)\n",
        "    model = SimpleNN(hidden_units=config['hidden_units'], dropout_rate=dropout_rate)\n",
        "    model.to(device)\n",
        "\n",
        "    # Set up optimizer with weight decay.\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=config['learning_rate'],\n",
        "        momentum=config['momentum'],\n",
        "        weight_decay=config['weight_decay']\n",
        "    )\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "    patience = config.get('patience', None)  # No early stopping if not provided.\n",
        "\n",
        "    epoch_losses = []\n",
        "    epoch_accs = []\n",
        "\n",
        "    for epoch in range(config['num_epochs']):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "        epoch_losses.append(val_loss)\n",
        "        epoch_accs.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config['num_epochs']}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "        # Log per-epoch metrics.\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_acc,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_acc\n",
        "        })\n",
        "\n",
        "        # Always update best_val_loss.\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            if patience is not None:\n",
        "                epochs_without_improvement += 1\n",
        "                if epochs_without_improvement >= patience:\n",
        "                    print(\"Early stopping triggered!\")\n",
        "                    break\n",
        "\n",
        "    return best_val_loss, epoch_losses, epoch_accs\n"
      ],
      "metadata": {
        "id": "7x8JV4MQTYrL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Experimental Setup\n",
        "A. Baseline :\n",
        "\n",
        "Configuration with 200 hidden units, zero weight decay, 100 epochs (≈1000 iterations with batch size 100), learning rate of 0.40, momentum of 0.9, and no early stopping."
      ],
      "metadata": {
        "id": "zIENrxgrTa3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1 configuration\n",
        "exp1_config = {\n",
        "    'hidden_units': 200,\n",
        "    'dropout_rate': 0.5,  # added dropout_rate\n",
        "    'weight_decay': 0.0,\n",
        "    'learning_rate': 0.40,\n",
        "    'momentum': 0.9,\n",
        "    'num_epochs': 100,\n",
        "    'batch_size': 100\n",
        "}\n",
        "\n",
        "print(\"Starting Experiment 1: Basic Configuration\")\n",
        "val_loss_exp1, epoch_losses_exp1, epoch_accs_exp1 = run_experiment(exp1_config)\n",
        "print(f\"Experiment 1 Final Validation Loss: {val_loss_exp1:.4f}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Plot the validation loss curve.\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epoch_losses_exp1, marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.title('Experiment 1: Validation Loss Curve')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Save the figure to a BytesIO buffer.\n",
        "buf = io.BytesIO()\n",
        "plt.savefig(buf, format='png')\n",
        "buf.seek(0)\n",
        "\n",
        "# Open the image with PIL and log it to wandb.\n",
        "img = Image.open(buf)\n",
        "wandb.log({\"Exp1_Val_Loss_Curve\": wandb.Image(img)})\n",
        "\n",
        "# Optionally, simulate logging some additional metrics (like in your sample snippet)\n",
        "import random\n",
        "epochs = 10\n",
        "offset = random.random() / 5\n",
        "for epoch in range(2, epochs):\n",
        "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
        "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
        "    wandb.log({\"simulated_acc\": acc, \"simulated_loss\": loss})\n",
        "\n",
        "# Mark the run as finished.\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g3TOK_xOTeBW",
        "outputId": "90bda810-0b1b-48ee-d9a9-5f73a305419a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Experiment 1: Basic Configuration\n",
            "Epoch 1/100: Train Loss=3.2482, Val Loss=2.4049, Val Acc=0.3630\n",
            "Epoch 2/100: Train Loss=1.8037, Val Loss=1.3622, Val Acc=0.5540\n",
            "Epoch 3/100: Train Loss=1.1381, Val Loss=0.8138, Val Acc=0.7540\n",
            "Epoch 4/100: Train Loss=0.7676, Val Loss=0.5322, Val Acc=0.8260\n",
            "Epoch 5/100: Train Loss=0.5309, Val Loss=0.4296, Val Acc=0.8730\n",
            "Epoch 6/100: Train Loss=0.4240, Val Loss=0.3436, Val Acc=0.9010\n",
            "Epoch 7/100: Train Loss=0.3240, Val Loss=0.2776, Val Acc=0.9290\n",
            "Epoch 8/100: Train Loss=0.2729, Val Loss=0.2594, Val Acc=0.9330\n",
            "Epoch 9/100: Train Loss=0.2242, Val Loss=0.2506, Val Acc=0.9350\n",
            "Epoch 10/100: Train Loss=0.2151, Val Loss=0.2526, Val Acc=0.9360\n",
            "Epoch 11/100: Train Loss=0.1825, Val Loss=0.2515, Val Acc=0.9290\n",
            "Epoch 12/100: Train Loss=0.1864, Val Loss=0.2378, Val Acc=0.9330\n",
            "Epoch 13/100: Train Loss=0.1900, Val Loss=0.2338, Val Acc=0.9330\n",
            "Epoch 14/100: Train Loss=0.1528, Val Loss=0.2272, Val Acc=0.9330\n",
            "Epoch 15/100: Train Loss=0.1296, Val Loss=0.2233, Val Acc=0.9360\n",
            "Epoch 16/100: Train Loss=0.1275, Val Loss=0.2191, Val Acc=0.9400\n",
            "Epoch 17/100: Train Loss=0.1090, Val Loss=0.2340, Val Acc=0.9340\n",
            "Epoch 18/100: Train Loss=0.1177, Val Loss=0.2196, Val Acc=0.9380\n",
            "Epoch 19/100: Train Loss=0.1048, Val Loss=0.2330, Val Acc=0.9340\n",
            "Epoch 20/100: Train Loss=0.1077, Val Loss=0.2168, Val Acc=0.9390\n",
            "Epoch 21/100: Train Loss=0.0882, Val Loss=0.2301, Val Acc=0.9410\n",
            "Epoch 22/100: Train Loss=0.0968, Val Loss=0.2209, Val Acc=0.9420\n",
            "Epoch 23/100: Train Loss=0.0826, Val Loss=0.2198, Val Acc=0.9370\n",
            "Epoch 24/100: Train Loss=0.1022, Val Loss=0.2222, Val Acc=0.9360\n",
            "Epoch 25/100: Train Loss=0.0660, Val Loss=0.2297, Val Acc=0.9360\n",
            "Epoch 26/100: Train Loss=0.0752, Val Loss=0.2188, Val Acc=0.9390\n",
            "Epoch 27/100: Train Loss=0.0675, Val Loss=0.2281, Val Acc=0.9390\n",
            "Epoch 28/100: Train Loss=0.0667, Val Loss=0.2343, Val Acc=0.9360\n",
            "Epoch 29/100: Train Loss=0.0670, Val Loss=0.2236, Val Acc=0.9340\n",
            "Epoch 30/100: Train Loss=0.0684, Val Loss=0.2256, Val Acc=0.9360\n",
            "Epoch 31/100: Train Loss=0.0655, Val Loss=0.2312, Val Acc=0.9390\n",
            "Epoch 32/100: Train Loss=0.0749, Val Loss=0.2284, Val Acc=0.9360\n",
            "Epoch 33/100: Train Loss=0.0641, Val Loss=0.2329, Val Acc=0.9390\n",
            "Epoch 34/100: Train Loss=0.0689, Val Loss=0.2283, Val Acc=0.9360\n",
            "Epoch 35/100: Train Loss=0.0487, Val Loss=0.2257, Val Acc=0.9390\n",
            "Epoch 36/100: Train Loss=0.0533, Val Loss=0.2367, Val Acc=0.9400\n",
            "Epoch 37/100: Train Loss=0.0507, Val Loss=0.2349, Val Acc=0.9400\n",
            "Epoch 38/100: Train Loss=0.0449, Val Loss=0.2341, Val Acc=0.9360\n",
            "Epoch 39/100: Train Loss=0.0469, Val Loss=0.2501, Val Acc=0.9380\n",
            "Epoch 40/100: Train Loss=0.0424, Val Loss=0.2446, Val Acc=0.9390\n",
            "Epoch 41/100: Train Loss=0.0545, Val Loss=0.2377, Val Acc=0.9400\n",
            "Epoch 42/100: Train Loss=0.0405, Val Loss=0.2351, Val Acc=0.9360\n",
            "Epoch 43/100: Train Loss=0.0365, Val Loss=0.2373, Val Acc=0.9360\n",
            "Epoch 44/100: Train Loss=0.0480, Val Loss=0.2429, Val Acc=0.9350\n",
            "Epoch 45/100: Train Loss=0.0441, Val Loss=0.2412, Val Acc=0.9350\n",
            "Epoch 46/100: Train Loss=0.0408, Val Loss=0.2504, Val Acc=0.9340\n",
            "Epoch 47/100: Train Loss=0.0326, Val Loss=0.2603, Val Acc=0.9350\n",
            "Epoch 48/100: Train Loss=0.0351, Val Loss=0.2538, Val Acc=0.9370\n",
            "Epoch 49/100: Train Loss=0.0405, Val Loss=0.2509, Val Acc=0.9390\n",
            "Epoch 50/100: Train Loss=0.0328, Val Loss=0.2549, Val Acc=0.9360\n",
            "Epoch 51/100: Train Loss=0.0396, Val Loss=0.2475, Val Acc=0.9370\n",
            "Epoch 52/100: Train Loss=0.0319, Val Loss=0.2479, Val Acc=0.9380\n",
            "Epoch 53/100: Train Loss=0.0325, Val Loss=0.2527, Val Acc=0.9410\n",
            "Epoch 54/100: Train Loss=0.0318, Val Loss=0.2536, Val Acc=0.9410\n",
            "Epoch 55/100: Train Loss=0.0315, Val Loss=0.2495, Val Acc=0.9390\n",
            "Epoch 56/100: Train Loss=0.0307, Val Loss=0.2522, Val Acc=0.9400\n",
            "Epoch 57/100: Train Loss=0.0246, Val Loss=0.2506, Val Acc=0.9380\n",
            "Epoch 58/100: Train Loss=0.0339, Val Loss=0.2488, Val Acc=0.9390\n",
            "Epoch 59/100: Train Loss=0.0267, Val Loss=0.2633, Val Acc=0.9370\n",
            "Epoch 60/100: Train Loss=0.0234, Val Loss=0.2689, Val Acc=0.9390\n",
            "Epoch 61/100: Train Loss=0.0331, Val Loss=0.2760, Val Acc=0.9400\n",
            "Epoch 62/100: Train Loss=0.0326, Val Loss=0.2636, Val Acc=0.9400\n",
            "Epoch 63/100: Train Loss=0.0233, Val Loss=0.2562, Val Acc=0.9390\n",
            "Epoch 64/100: Train Loss=0.0362, Val Loss=0.2716, Val Acc=0.9390\n",
            "Epoch 65/100: Train Loss=0.0440, Val Loss=0.2535, Val Acc=0.9380\n",
            "Epoch 66/100: Train Loss=0.0302, Val Loss=0.2585, Val Acc=0.9380\n",
            "Epoch 67/100: Train Loss=0.0365, Val Loss=0.2659, Val Acc=0.9350\n",
            "Epoch 68/100: Train Loss=0.0209, Val Loss=0.2664, Val Acc=0.9390\n",
            "Epoch 69/100: Train Loss=0.0181, Val Loss=0.2741, Val Acc=0.9390\n",
            "Epoch 70/100: Train Loss=0.0236, Val Loss=0.2769, Val Acc=0.9380\n",
            "Epoch 71/100: Train Loss=0.0265, Val Loss=0.2800, Val Acc=0.9380\n",
            "Epoch 72/100: Train Loss=0.0248, Val Loss=0.2737, Val Acc=0.9380\n",
            "Epoch 73/100: Train Loss=0.0331, Val Loss=0.2764, Val Acc=0.9390\n",
            "Epoch 74/100: Train Loss=0.0217, Val Loss=0.2680, Val Acc=0.9370\n",
            "Epoch 75/100: Train Loss=0.0285, Val Loss=0.2704, Val Acc=0.9380\n",
            "Epoch 76/100: Train Loss=0.0199, Val Loss=0.2710, Val Acc=0.9380\n",
            "Epoch 77/100: Train Loss=0.0197, Val Loss=0.2634, Val Acc=0.9410\n",
            "Epoch 78/100: Train Loss=0.0209, Val Loss=0.2641, Val Acc=0.9400\n",
            "Epoch 79/100: Train Loss=0.0220, Val Loss=0.2567, Val Acc=0.9380\n",
            "Epoch 80/100: Train Loss=0.0298, Val Loss=0.2642, Val Acc=0.9390\n",
            "Epoch 81/100: Train Loss=0.0189, Val Loss=0.2753, Val Acc=0.9370\n",
            "Epoch 82/100: Train Loss=0.0178, Val Loss=0.2743, Val Acc=0.9390\n",
            "Epoch 83/100: Train Loss=0.0189, Val Loss=0.2670, Val Acc=0.9400\n",
            "Epoch 84/100: Train Loss=0.0188, Val Loss=0.2645, Val Acc=0.9400\n",
            "Epoch 85/100: Train Loss=0.0227, Val Loss=0.2688, Val Acc=0.9380\n",
            "Epoch 86/100: Train Loss=0.0200, Val Loss=0.2737, Val Acc=0.9350\n",
            "Epoch 87/100: Train Loss=0.0264, Val Loss=0.2825, Val Acc=0.9330\n",
            "Epoch 88/100: Train Loss=0.0229, Val Loss=0.2857, Val Acc=0.9350\n",
            "Epoch 89/100: Train Loss=0.0201, Val Loss=0.2822, Val Acc=0.9370\n",
            "Epoch 90/100: Train Loss=0.0173, Val Loss=0.2774, Val Acc=0.9360\n",
            "Epoch 91/100: Train Loss=0.0270, Val Loss=0.2728, Val Acc=0.9370\n",
            "Epoch 92/100: Train Loss=0.0168, Val Loss=0.2648, Val Acc=0.9400\n",
            "Epoch 93/100: Train Loss=0.0189, Val Loss=0.2656, Val Acc=0.9420\n",
            "Epoch 94/100: Train Loss=0.0156, Val Loss=0.2750, Val Acc=0.9350\n",
            "Epoch 95/100: Train Loss=0.0212, Val Loss=0.2744, Val Acc=0.9370\n",
            "Epoch 96/100: Train Loss=0.0182, Val Loss=0.2778, Val Acc=0.9390\n",
            "Epoch 97/100: Train Loss=0.0162, Val Loss=0.2813, Val Acc=0.9420\n",
            "Epoch 98/100: Train Loss=0.0171, Val Loss=0.2788, Val Acc=0.9360\n",
            "Epoch 99/100: Train Loss=0.0152, Val Loss=0.2695, Val Acc=0.9360\n",
            "Epoch 100/100: Train Loss=0.0118, Val Loss=0.2707, Val Acc=0.9360\n",
            "Experiment 1 Final Validation Loss: 0.2168\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>simulated_acc</td><td>▁▃▄█▆█▇█</td></tr><tr><td>simulated_loss</td><td>█▃▄▁▂▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆▆▇▇█████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆██████████████████████████████████████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>simulated_acc</td><td>0.8117</td></tr><tr><td>simulated_loss</td><td>0.17055</td></tr><tr><td>train_accuracy</td><td>0.998</td></tr><tr><td>train_loss</td><td>0.01183</td></tr><tr><td>val_accuracy</td><td>0.936</td></tr><tr><td>val_loss</td><td>0.27072</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">experiment_1</strong> at: <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/z06u9y4b' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/z06u9y4b</a><br> View project at: <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250217_093310-z06u9y4b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT ANALYSIS :\n",
        "\n",
        "Training Dynamics:\n",
        "The model converged quickly with a steady decrease in training loss, reaching a very low training loss of approximately 0.012 and an excellent training accuracy of 99.7%.\n",
        "\n",
        "Validation Performance:\n",
        "The validation loss reached a minimum of ~0.2100 during training, and the final validation accuracy is around 94.3%. These results indicate that the model generalizes well despite the high training accuracy.\n",
        "\n",
        "Overall Assessment:\n",
        "The use of SGD with momentum (learning rate = 0.40, momentum = 0.9) enabled rapid convergence, while dropout (with a dropout rate of 0.5) provided sufficient regularization to prevent overfitting. The run history from wandb confirms that the model's performance remains stable over 100 epochs, making this configuration a promising baseline for further hyperparameter tuning."
      ],
      "metadata": {
        "id": "ud8cO0u_Tkuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. Weight Decay Investigation :\n",
        "\n",
        "Testing different L2 weight decay coefficients: 0.0, 0.0001, 0.001, 0.01, 1, 2, and 5."
      ],
      "metadata": {
        "id": "-0ykLjmTTngH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reinitialize wandb if no active run exists.\n",
        "if wandb.run is None:\n",
        "    wandb.init(\n",
        "        project=\"usps-digit-classification\",\n",
        "        settings=wandb.Settings(init_timeout=600)\n",
        "    )\n",
        "\n",
        "weight_decay_values = [0.0, 0.0001, 0.001, 0.01, 1, 2, 5]\n",
        "results_wd = {}\n",
        "\n",
        "for wd in weight_decay_values:\n",
        "    config_wd = {\n",
        "        'hidden_units': 200,\n",
        "        'dropout_rate': 0.5,\n",
        "        'weight_decay': wd,\n",
        "        'learning_rate': 0.40,\n",
        "        'momentum': 0.9,\n",
        "        'num_epochs': 100,\n",
        "        'batch_size': 100\n",
        "    }\n",
        "    print(f\"\\nRunning Experiment 2 with weight decay = {wd}\")\n",
        "    val_loss, _, _ = run_experiment(config_wd)\n",
        "    results_wd[wd] = val_loss\n",
        "    print(f\"WD={wd} -> Val Loss: {val_loss:.4f}\")\n",
        "    wandb.log({f\"Exp2_ValLoss_WD_{wd}\": val_loss})\n",
        "\n",
        "# (Optional) Locally display the plot:\n",
        "plt.figure(figsize=(8, 5))\n",
        "# If any weight decay is zero, use linear scale; otherwise, log scale can be used.\n",
        "nonzero_wds = [wd for wd in weight_decay_values if wd > 0]\n",
        "if len(nonzero_wds) == len(weight_decay_values):\n",
        "    plt.xscale('log')\n",
        "else:\n",
        "    plt.xscale('linear')\n",
        "plt.plot(weight_decay_values, [results_wd[wd] for wd in weight_decay_values], marker='o')\n",
        "plt.xlabel('Weight Decay Coefficient')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.title('Experiment 2: Val Loss vs. Weight Decay')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "wandb.finish()  # End this run when done."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RzK1uW8-ToEU",
        "outputId": "07274e0e-82e6-45b3-ddbe-80eb41d98f77"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250217_100759-aiguldc7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/aiguldc7' target=\"_blank\">skilled-totem-2</a></strong> to <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/aiguldc7' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/aiguldc7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Experiment 2 with weight decay = 0.0\n",
            "Epoch 1/100: Train Loss=3.2210, Val Loss=2.1506, Val Acc=0.4030\n",
            "Epoch 2/100: Train Loss=1.8333, Val Loss=1.4024, Val Acc=0.5240\n",
            "Epoch 3/100: Train Loss=1.2072, Val Loss=0.9866, Val Acc=0.7360\n",
            "Epoch 4/100: Train Loss=0.8623, Val Loss=0.6456, Val Acc=0.8160\n",
            "Epoch 5/100: Train Loss=0.5916, Val Loss=0.4436, Val Acc=0.8790\n",
            "Epoch 6/100: Train Loss=0.4620, Val Loss=0.3528, Val Acc=0.9050\n",
            "Epoch 7/100: Train Loss=0.3791, Val Loss=0.3135, Val Acc=0.9200\n",
            "Epoch 8/100: Train Loss=0.3020, Val Loss=0.2870, Val Acc=0.9240\n",
            "Epoch 9/100: Train Loss=0.2728, Val Loss=0.2792, Val Acc=0.9250\n",
            "Epoch 10/100: Train Loss=0.2566, Val Loss=0.2601, Val Acc=0.9350\n",
            "Epoch 11/100: Train Loss=0.2314, Val Loss=0.2687, Val Acc=0.9270\n",
            "Epoch 12/100: Train Loss=0.2176, Val Loss=0.2517, Val Acc=0.9350\n",
            "Epoch 13/100: Train Loss=0.1826, Val Loss=0.2595, Val Acc=0.9290\n",
            "Epoch 14/100: Train Loss=0.1716, Val Loss=0.2557, Val Acc=0.9290\n",
            "Epoch 15/100: Train Loss=0.1466, Val Loss=0.2381, Val Acc=0.9350\n",
            "Epoch 16/100: Train Loss=0.1462, Val Loss=0.2386, Val Acc=0.9320\n",
            "Epoch 17/100: Train Loss=0.1369, Val Loss=0.2422, Val Acc=0.9300\n",
            "Epoch 18/100: Train Loss=0.1283, Val Loss=0.2465, Val Acc=0.9300\n",
            "Epoch 19/100: Train Loss=0.1190, Val Loss=0.2339, Val Acc=0.9350\n",
            "Epoch 20/100: Train Loss=0.1079, Val Loss=0.2441, Val Acc=0.9310\n",
            "Epoch 21/100: Train Loss=0.1033, Val Loss=0.2453, Val Acc=0.9320\n",
            "Epoch 22/100: Train Loss=0.1034, Val Loss=0.2377, Val Acc=0.9300\n",
            "Epoch 23/100: Train Loss=0.0892, Val Loss=0.2457, Val Acc=0.9310\n",
            "Epoch 24/100: Train Loss=0.0760, Val Loss=0.2450, Val Acc=0.9340\n",
            "Epoch 25/100: Train Loss=0.0903, Val Loss=0.2409, Val Acc=0.9340\n",
            "Epoch 26/100: Train Loss=0.0802, Val Loss=0.2387, Val Acc=0.9310\n",
            "Epoch 27/100: Train Loss=0.0815, Val Loss=0.2446, Val Acc=0.9320\n",
            "Epoch 28/100: Train Loss=0.0724, Val Loss=0.2631, Val Acc=0.9360\n",
            "Epoch 29/100: Train Loss=0.0830, Val Loss=0.2637, Val Acc=0.9300\n",
            "Epoch 30/100: Train Loss=0.0784, Val Loss=0.2532, Val Acc=0.9340\n",
            "Epoch 31/100: Train Loss=0.0606, Val Loss=0.2475, Val Acc=0.9370\n",
            "Epoch 32/100: Train Loss=0.0742, Val Loss=0.2590, Val Acc=0.9360\n",
            "Epoch 33/100: Train Loss=0.0657, Val Loss=0.2616, Val Acc=0.9300\n",
            "Epoch 34/100: Train Loss=0.0698, Val Loss=0.2589, Val Acc=0.9320\n",
            "Epoch 35/100: Train Loss=0.0650, Val Loss=0.2550, Val Acc=0.9350\n",
            "Epoch 36/100: Train Loss=0.0496, Val Loss=0.2625, Val Acc=0.9290\n",
            "Epoch 37/100: Train Loss=0.0576, Val Loss=0.2523, Val Acc=0.9310\n",
            "Epoch 38/100: Train Loss=0.0578, Val Loss=0.2556, Val Acc=0.9360\n",
            "Epoch 39/100: Train Loss=0.0442, Val Loss=0.2629, Val Acc=0.9370\n",
            "Epoch 40/100: Train Loss=0.0434, Val Loss=0.2613, Val Acc=0.9340\n",
            "Epoch 41/100: Train Loss=0.0534, Val Loss=0.2602, Val Acc=0.9350\n",
            "Epoch 42/100: Train Loss=0.0596, Val Loss=0.2607, Val Acc=0.9390\n",
            "Epoch 43/100: Train Loss=0.0552, Val Loss=0.2720, Val Acc=0.9360\n",
            "Epoch 44/100: Train Loss=0.0489, Val Loss=0.2629, Val Acc=0.9400\n",
            "Epoch 45/100: Train Loss=0.0436, Val Loss=0.2691, Val Acc=0.9350\n",
            "Epoch 46/100: Train Loss=0.0366, Val Loss=0.2653, Val Acc=0.9350\n",
            "Epoch 47/100: Train Loss=0.0465, Val Loss=0.2819, Val Acc=0.9330\n",
            "Epoch 48/100: Train Loss=0.0388, Val Loss=0.2833, Val Acc=0.9360\n",
            "Epoch 49/100: Train Loss=0.0400, Val Loss=0.2723, Val Acc=0.9340\n",
            "Epoch 50/100: Train Loss=0.0544, Val Loss=0.2763, Val Acc=0.9370\n",
            "Epoch 51/100: Train Loss=0.0452, Val Loss=0.2795, Val Acc=0.9400\n",
            "Epoch 52/100: Train Loss=0.0294, Val Loss=0.2734, Val Acc=0.9350\n",
            "Epoch 53/100: Train Loss=0.0295, Val Loss=0.2750, Val Acc=0.9340\n",
            "Epoch 54/100: Train Loss=0.0319, Val Loss=0.2779, Val Acc=0.9320\n",
            "Epoch 55/100: Train Loss=0.0351, Val Loss=0.2726, Val Acc=0.9330\n",
            "Epoch 56/100: Train Loss=0.0316, Val Loss=0.2868, Val Acc=0.9340\n",
            "Epoch 57/100: Train Loss=0.0411, Val Loss=0.2799, Val Acc=0.9350\n",
            "Epoch 58/100: Train Loss=0.0303, Val Loss=0.2863, Val Acc=0.9340\n",
            "Epoch 59/100: Train Loss=0.0353, Val Loss=0.2951, Val Acc=0.9320\n",
            "Epoch 60/100: Train Loss=0.0329, Val Loss=0.2819, Val Acc=0.9340\n",
            "Epoch 61/100: Train Loss=0.0318, Val Loss=0.2799, Val Acc=0.9330\n",
            "Epoch 62/100: Train Loss=0.0281, Val Loss=0.2856, Val Acc=0.9330\n",
            "Epoch 63/100: Train Loss=0.0359, Val Loss=0.2881, Val Acc=0.9310\n",
            "Epoch 64/100: Train Loss=0.0279, Val Loss=0.2893, Val Acc=0.9320\n",
            "Epoch 65/100: Train Loss=0.0277, Val Loss=0.2765, Val Acc=0.9330\n",
            "Epoch 66/100: Train Loss=0.0260, Val Loss=0.2763, Val Acc=0.9370\n",
            "Epoch 67/100: Train Loss=0.0269, Val Loss=0.2761, Val Acc=0.9360\n",
            "Epoch 68/100: Train Loss=0.0269, Val Loss=0.2808, Val Acc=0.9350\n",
            "Epoch 69/100: Train Loss=0.0269, Val Loss=0.2822, Val Acc=0.9360\n",
            "Epoch 70/100: Train Loss=0.0193, Val Loss=0.2808, Val Acc=0.9360\n",
            "Epoch 71/100: Train Loss=0.0323, Val Loss=0.2885, Val Acc=0.9350\n",
            "Epoch 72/100: Train Loss=0.0218, Val Loss=0.2913, Val Acc=0.9340\n",
            "Epoch 73/100: Train Loss=0.0183, Val Loss=0.2968, Val Acc=0.9340\n",
            "Epoch 74/100: Train Loss=0.0220, Val Loss=0.2878, Val Acc=0.9350\n",
            "Epoch 75/100: Train Loss=0.0313, Val Loss=0.2918, Val Acc=0.9410\n",
            "Epoch 76/100: Train Loss=0.0260, Val Loss=0.2995, Val Acc=0.9340\n",
            "Epoch 77/100: Train Loss=0.0339, Val Loss=0.2892, Val Acc=0.9360\n",
            "Epoch 78/100: Train Loss=0.0234, Val Loss=0.2941, Val Acc=0.9370\n",
            "Epoch 79/100: Train Loss=0.0230, Val Loss=0.2846, Val Acc=0.9350\n",
            "Epoch 80/100: Train Loss=0.0263, Val Loss=0.2878, Val Acc=0.9340\n",
            "Epoch 81/100: Train Loss=0.0277, Val Loss=0.3036, Val Acc=0.9380\n",
            "Epoch 82/100: Train Loss=0.0204, Val Loss=0.3040, Val Acc=0.9380\n",
            "Epoch 83/100: Train Loss=0.0175, Val Loss=0.2896, Val Acc=0.9380\n",
            "Epoch 84/100: Train Loss=0.0220, Val Loss=0.2924, Val Acc=0.9350\n",
            "Epoch 85/100: Train Loss=0.0244, Val Loss=0.2937, Val Acc=0.9340\n",
            "Epoch 86/100: Train Loss=0.0228, Val Loss=0.2910, Val Acc=0.9350\n",
            "Epoch 87/100: Train Loss=0.0298, Val Loss=0.2983, Val Acc=0.9310\n",
            "Epoch 88/100: Train Loss=0.0241, Val Loss=0.2980, Val Acc=0.9350\n",
            "Epoch 89/100: Train Loss=0.0210, Val Loss=0.2961, Val Acc=0.9350\n",
            "Epoch 90/100: Train Loss=0.0211, Val Loss=0.2937, Val Acc=0.9340\n",
            "Epoch 91/100: Train Loss=0.0114, Val Loss=0.2929, Val Acc=0.9360\n",
            "Epoch 92/100: Train Loss=0.0141, Val Loss=0.2907, Val Acc=0.9340\n",
            "Epoch 93/100: Train Loss=0.0196, Val Loss=0.2957, Val Acc=0.9330\n",
            "Epoch 94/100: Train Loss=0.0180, Val Loss=0.3020, Val Acc=0.9330\n",
            "Epoch 95/100: Train Loss=0.0188, Val Loss=0.2938, Val Acc=0.9410\n",
            "Epoch 96/100: Train Loss=0.0273, Val Loss=0.2905, Val Acc=0.9350\n",
            "Epoch 97/100: Train Loss=0.0211, Val Loss=0.2898, Val Acc=0.9330\n",
            "Epoch 98/100: Train Loss=0.0184, Val Loss=0.2894, Val Acc=0.9340\n",
            "Epoch 99/100: Train Loss=0.0212, Val Loss=0.2887, Val Acc=0.9400\n",
            "Epoch 100/100: Train Loss=0.0154, Val Loss=0.2939, Val Acc=0.9400\n",
            "WD=0.0 -> Val Loss: 0.2339\n",
            "\n",
            "Running Experiment 2 with weight decay = 0.0001\n",
            "Epoch 1/100: Train Loss=2.4597, Val Loss=2.1062, Val Acc=0.3080\n",
            "Epoch 2/100: Train Loss=1.3562, Val Loss=0.7701, Val Acc=0.7930\n",
            "Epoch 3/100: Train Loss=0.6097, Val Loss=0.4226, Val Acc=0.8680\n",
            "Epoch 4/100: Train Loss=0.3823, Val Loss=0.3134, Val Acc=0.9010\n",
            "Epoch 5/100: Train Loss=0.3232, Val Loss=0.3147, Val Acc=0.9100\n",
            "Epoch 6/100: Train Loss=0.2383, Val Loss=0.2773, Val Acc=0.9160\n",
            "Epoch 7/100: Train Loss=0.1994, Val Loss=0.2802, Val Acc=0.9220\n",
            "Epoch 8/100: Train Loss=0.1823, Val Loss=0.2467, Val Acc=0.9250\n",
            "Epoch 9/100: Train Loss=0.1799, Val Loss=0.2663, Val Acc=0.9250\n",
            "Epoch 10/100: Train Loss=0.1572, Val Loss=0.2442, Val Acc=0.9270\n",
            "Epoch 11/100: Train Loss=0.1321, Val Loss=0.2355, Val Acc=0.9330\n",
            "Epoch 12/100: Train Loss=0.1244, Val Loss=0.2370, Val Acc=0.9370\n",
            "Epoch 13/100: Train Loss=0.1051, Val Loss=0.2199, Val Acc=0.9330\n",
            "Epoch 14/100: Train Loss=0.1092, Val Loss=0.2274, Val Acc=0.9320\n",
            "Epoch 15/100: Train Loss=0.0952, Val Loss=0.2280, Val Acc=0.9340\n",
            "Epoch 16/100: Train Loss=0.0917, Val Loss=0.2266, Val Acc=0.9360\n",
            "Epoch 17/100: Train Loss=0.0805, Val Loss=0.2376, Val Acc=0.9360\n",
            "Epoch 18/100: Train Loss=0.0991, Val Loss=0.2329, Val Acc=0.9310\n",
            "Epoch 19/100: Train Loss=0.0752, Val Loss=0.2314, Val Acc=0.9360\n",
            "Epoch 20/100: Train Loss=0.0716, Val Loss=0.2380, Val Acc=0.9310\n",
            "Epoch 21/100: Train Loss=0.0670, Val Loss=0.2356, Val Acc=0.9360\n",
            "Epoch 22/100: Train Loss=0.0688, Val Loss=0.2337, Val Acc=0.9330\n",
            "Epoch 23/100: Train Loss=0.0621, Val Loss=0.2378, Val Acc=0.9360\n",
            "Epoch 24/100: Train Loss=0.0646, Val Loss=0.2369, Val Acc=0.9390\n",
            "Epoch 25/100: Train Loss=0.0626, Val Loss=0.2528, Val Acc=0.9330\n",
            "Epoch 26/100: Train Loss=0.0610, Val Loss=0.2386, Val Acc=0.9370\n",
            "Epoch 27/100: Train Loss=0.0493, Val Loss=0.2265, Val Acc=0.9360\n",
            "Epoch 28/100: Train Loss=0.0503, Val Loss=0.2409, Val Acc=0.9340\n",
            "Epoch 29/100: Train Loss=0.0537, Val Loss=0.2369, Val Acc=0.9390\n",
            "Epoch 30/100: Train Loss=0.0435, Val Loss=0.2315, Val Acc=0.9380\n",
            "Epoch 31/100: Train Loss=0.0450, Val Loss=0.2340, Val Acc=0.9390\n",
            "Epoch 32/100: Train Loss=0.0433, Val Loss=0.2456, Val Acc=0.9380\n",
            "Epoch 33/100: Train Loss=0.0455, Val Loss=0.2521, Val Acc=0.9300\n",
            "Epoch 34/100: Train Loss=0.0334, Val Loss=0.2423, Val Acc=0.9300\n",
            "Epoch 35/100: Train Loss=0.0453, Val Loss=0.2473, Val Acc=0.9350\n",
            "Epoch 36/100: Train Loss=0.0425, Val Loss=0.2396, Val Acc=0.9390\n",
            "Epoch 37/100: Train Loss=0.0433, Val Loss=0.2543, Val Acc=0.9350\n",
            "Epoch 38/100: Train Loss=0.0380, Val Loss=0.2486, Val Acc=0.9370\n",
            "Epoch 39/100: Train Loss=0.0439, Val Loss=0.2348, Val Acc=0.9430\n",
            "Epoch 40/100: Train Loss=0.0353, Val Loss=0.2385, Val Acc=0.9340\n",
            "Epoch 41/100: Train Loss=0.0336, Val Loss=0.2347, Val Acc=0.9370\n",
            "Epoch 42/100: Train Loss=0.0317, Val Loss=0.2494, Val Acc=0.9370\n",
            "Epoch 43/100: Train Loss=0.0320, Val Loss=0.2550, Val Acc=0.9370\n",
            "Epoch 44/100: Train Loss=0.0225, Val Loss=0.2598, Val Acc=0.9360\n",
            "Epoch 45/100: Train Loss=0.0347, Val Loss=0.2533, Val Acc=0.9360\n",
            "Epoch 46/100: Train Loss=0.0299, Val Loss=0.2501, Val Acc=0.9370\n",
            "Epoch 47/100: Train Loss=0.0397, Val Loss=0.2570, Val Acc=0.9390\n",
            "Epoch 48/100: Train Loss=0.0328, Val Loss=0.2373, Val Acc=0.9380\n",
            "Epoch 49/100: Train Loss=0.0308, Val Loss=0.2417, Val Acc=0.9400\n",
            "Epoch 50/100: Train Loss=0.0312, Val Loss=0.2458, Val Acc=0.9450\n",
            "Epoch 51/100: Train Loss=0.0250, Val Loss=0.2500, Val Acc=0.9340\n",
            "Epoch 52/100: Train Loss=0.0333, Val Loss=0.2406, Val Acc=0.9350\n",
            "Epoch 53/100: Train Loss=0.0259, Val Loss=0.2535, Val Acc=0.9370\n",
            "Epoch 54/100: Train Loss=0.0335, Val Loss=0.2530, Val Acc=0.9380\n",
            "Epoch 55/100: Train Loss=0.0335, Val Loss=0.2407, Val Acc=0.9390\n",
            "Epoch 56/100: Train Loss=0.0350, Val Loss=0.2532, Val Acc=0.9330\n",
            "Epoch 57/100: Train Loss=0.0208, Val Loss=0.2531, Val Acc=0.9370\n",
            "Epoch 58/100: Train Loss=0.0272, Val Loss=0.2456, Val Acc=0.9380\n",
            "Epoch 59/100: Train Loss=0.0300, Val Loss=0.2429, Val Acc=0.9410\n",
            "Epoch 60/100: Train Loss=0.0223, Val Loss=0.2509, Val Acc=0.9360\n",
            "Epoch 61/100: Train Loss=0.0238, Val Loss=0.2415, Val Acc=0.9420\n",
            "Epoch 62/100: Train Loss=0.0239, Val Loss=0.2405, Val Acc=0.9440\n",
            "Epoch 63/100: Train Loss=0.0210, Val Loss=0.2310, Val Acc=0.9370\n",
            "Epoch 64/100: Train Loss=0.0284, Val Loss=0.2362, Val Acc=0.9410\n",
            "Epoch 65/100: Train Loss=0.0226, Val Loss=0.2410, Val Acc=0.9360\n",
            "Epoch 66/100: Train Loss=0.0310, Val Loss=0.2406, Val Acc=0.9390\n",
            "Epoch 67/100: Train Loss=0.0286, Val Loss=0.2393, Val Acc=0.9410\n",
            "Epoch 68/100: Train Loss=0.0215, Val Loss=0.2554, Val Acc=0.9370\n",
            "Epoch 69/100: Train Loss=0.0288, Val Loss=0.2408, Val Acc=0.9430\n",
            "Epoch 70/100: Train Loss=0.0259, Val Loss=0.2455, Val Acc=0.9380\n",
            "Epoch 71/100: Train Loss=0.0239, Val Loss=0.2508, Val Acc=0.9410\n",
            "Epoch 72/100: Train Loss=0.0259, Val Loss=0.2511, Val Acc=0.9390\n",
            "Epoch 73/100: Train Loss=0.0255, Val Loss=0.2290, Val Acc=0.9400\n",
            "Epoch 74/100: Train Loss=0.0304, Val Loss=0.2385, Val Acc=0.9400\n",
            "Epoch 75/100: Train Loss=0.0287, Val Loss=0.2537, Val Acc=0.9360\n",
            "Epoch 76/100: Train Loss=0.0255, Val Loss=0.2427, Val Acc=0.9340\n",
            "Epoch 77/100: Train Loss=0.0238, Val Loss=0.2532, Val Acc=0.9370\n",
            "Epoch 78/100: Train Loss=0.0230, Val Loss=0.2532, Val Acc=0.9400\n",
            "Epoch 79/100: Train Loss=0.0182, Val Loss=0.2590, Val Acc=0.9350\n",
            "Epoch 80/100: Train Loss=0.0140, Val Loss=0.2475, Val Acc=0.9360\n",
            "Epoch 81/100: Train Loss=0.0192, Val Loss=0.2537, Val Acc=0.9390\n",
            "Epoch 82/100: Train Loss=0.0258, Val Loss=0.2458, Val Acc=0.9380\n",
            "Epoch 83/100: Train Loss=0.0168, Val Loss=0.2505, Val Acc=0.9390\n",
            "Epoch 84/100: Train Loss=0.0225, Val Loss=0.2499, Val Acc=0.9390\n",
            "Epoch 85/100: Train Loss=0.0198, Val Loss=0.2503, Val Acc=0.9350\n",
            "Epoch 86/100: Train Loss=0.0337, Val Loss=0.2501, Val Acc=0.9350\n",
            "Epoch 87/100: Train Loss=0.0164, Val Loss=0.2565, Val Acc=0.9360\n",
            "Epoch 88/100: Train Loss=0.0193, Val Loss=0.2537, Val Acc=0.9380\n",
            "Epoch 89/100: Train Loss=0.0193, Val Loss=0.2516, Val Acc=0.9390\n",
            "Epoch 90/100: Train Loss=0.0264, Val Loss=0.2556, Val Acc=0.9420\n",
            "Epoch 91/100: Train Loss=0.0171, Val Loss=0.2547, Val Acc=0.9350\n",
            "Epoch 92/100: Train Loss=0.0198, Val Loss=0.2512, Val Acc=0.9390\n",
            "Epoch 93/100: Train Loss=0.0201, Val Loss=0.2586, Val Acc=0.9420\n",
            "Epoch 94/100: Train Loss=0.0232, Val Loss=0.2689, Val Acc=0.9360\n",
            "Epoch 95/100: Train Loss=0.0220, Val Loss=0.2539, Val Acc=0.9370\n",
            "Epoch 96/100: Train Loss=0.0162, Val Loss=0.2623, Val Acc=0.9380\n",
            "Epoch 97/100: Train Loss=0.0205, Val Loss=0.2523, Val Acc=0.9370\n",
            "Epoch 98/100: Train Loss=0.0180, Val Loss=0.2612, Val Acc=0.9340\n",
            "Epoch 99/100: Train Loss=0.0197, Val Loss=0.2639, Val Acc=0.9380\n",
            "Epoch 100/100: Train Loss=0.0189, Val Loss=0.2552, Val Acc=0.9360\n",
            "WD=0.0001 -> Val Loss: 0.2199\n",
            "\n",
            "Running Experiment 2 with weight decay = 0.001\n",
            "Epoch 1/100: Train Loss=2.6361, Val Loss=1.9636, Val Acc=0.3270\n",
            "Epoch 2/100: Train Loss=1.3718, Val Loss=0.9052, Val Acc=0.7310\n",
            "Epoch 3/100: Train Loss=0.6954, Val Loss=0.5074, Val Acc=0.8220\n",
            "Epoch 4/100: Train Loss=0.4322, Val Loss=0.3491, Val Acc=0.8870\n",
            "Epoch 5/100: Train Loss=0.3153, Val Loss=0.3167, Val Acc=0.9060\n",
            "Epoch 6/100: Train Loss=0.3023, Val Loss=0.2707, Val Acc=0.9250\n",
            "Epoch 7/100: Train Loss=0.2562, Val Loss=0.2853, Val Acc=0.9210\n",
            "Epoch 8/100: Train Loss=0.2501, Val Loss=0.2597, Val Acc=0.9270\n",
            "Epoch 9/100: Train Loss=0.1838, Val Loss=0.2478, Val Acc=0.9290\n",
            "Epoch 10/100: Train Loss=0.2085, Val Loss=0.2497, Val Acc=0.9240\n",
            "Epoch 11/100: Train Loss=0.1840, Val Loss=0.2361, Val Acc=0.9270\n",
            "Epoch 12/100: Train Loss=0.1882, Val Loss=0.2453, Val Acc=0.9260\n",
            "Epoch 13/100: Train Loss=0.1898, Val Loss=0.2458, Val Acc=0.9280\n",
            "Epoch 14/100: Train Loss=0.1937, Val Loss=0.2586, Val Acc=0.9280\n",
            "Epoch 15/100: Train Loss=0.1756, Val Loss=0.2495, Val Acc=0.9240\n",
            "Epoch 16/100: Train Loss=0.1671, Val Loss=0.2823, Val Acc=0.9140\n",
            "Epoch 17/100: Train Loss=0.1718, Val Loss=0.2499, Val Acc=0.9280\n",
            "Epoch 18/100: Train Loss=0.1502, Val Loss=0.2350, Val Acc=0.9260\n",
            "Epoch 19/100: Train Loss=0.1585, Val Loss=0.2398, Val Acc=0.9300\n",
            "Epoch 20/100: Train Loss=0.1463, Val Loss=0.2764, Val Acc=0.9230\n",
            "Epoch 21/100: Train Loss=0.1717, Val Loss=0.2616, Val Acc=0.9180\n",
            "Epoch 22/100: Train Loss=0.1318, Val Loss=0.2292, Val Acc=0.9320\n",
            "Epoch 23/100: Train Loss=0.1336, Val Loss=0.2442, Val Acc=0.9250\n",
            "Epoch 24/100: Train Loss=0.1318, Val Loss=0.2333, Val Acc=0.9260\n",
            "Epoch 25/100: Train Loss=0.1422, Val Loss=0.2455, Val Acc=0.9290\n",
            "Epoch 26/100: Train Loss=0.1657, Val Loss=0.2310, Val Acc=0.9360\n",
            "Epoch 27/100: Train Loss=0.1346, Val Loss=0.2324, Val Acc=0.9290\n",
            "Epoch 28/100: Train Loss=0.1327, Val Loss=0.2283, Val Acc=0.9310\n",
            "Epoch 29/100: Train Loss=0.1200, Val Loss=0.2340, Val Acc=0.9350\n",
            "Epoch 30/100: Train Loss=0.1254, Val Loss=0.2394, Val Acc=0.9270\n",
            "Epoch 31/100: Train Loss=0.1314, Val Loss=0.2364, Val Acc=0.9270\n",
            "Epoch 32/100: Train Loss=0.1310, Val Loss=0.2579, Val Acc=0.9260\n",
            "Epoch 33/100: Train Loss=0.1421, Val Loss=0.2301, Val Acc=0.9250\n",
            "Epoch 34/100: Train Loss=0.1421, Val Loss=0.2343, Val Acc=0.9330\n",
            "Epoch 35/100: Train Loss=0.1346, Val Loss=0.2536, Val Acc=0.9290\n",
            "Epoch 36/100: Train Loss=0.1541, Val Loss=0.2301, Val Acc=0.9310\n",
            "Epoch 37/100: Train Loss=0.1306, Val Loss=0.2645, Val Acc=0.9180\n",
            "Epoch 38/100: Train Loss=0.1216, Val Loss=0.2376, Val Acc=0.9320\n",
            "Epoch 39/100: Train Loss=0.1132, Val Loss=0.2351, Val Acc=0.9280\n",
            "Epoch 40/100: Train Loss=0.1153, Val Loss=0.2221, Val Acc=0.9360\n",
            "Epoch 41/100: Train Loss=0.1207, Val Loss=0.2203, Val Acc=0.9340\n",
            "Epoch 42/100: Train Loss=0.1220, Val Loss=0.2493, Val Acc=0.9260\n",
            "Epoch 43/100: Train Loss=0.1330, Val Loss=0.2437, Val Acc=0.9330\n",
            "Epoch 44/100: Train Loss=0.1382, Val Loss=0.2289, Val Acc=0.9320\n",
            "Epoch 45/100: Train Loss=0.1274, Val Loss=0.2391, Val Acc=0.9300\n",
            "Epoch 46/100: Train Loss=0.1259, Val Loss=0.2370, Val Acc=0.9300\n",
            "Epoch 47/100: Train Loss=0.1239, Val Loss=0.2311, Val Acc=0.9340\n",
            "Epoch 48/100: Train Loss=0.1119, Val Loss=0.2321, Val Acc=0.9300\n",
            "Epoch 49/100: Train Loss=0.1206, Val Loss=0.2379, Val Acc=0.9290\n",
            "Epoch 50/100: Train Loss=0.1394, Val Loss=0.2435, Val Acc=0.9340\n",
            "Epoch 51/100: Train Loss=0.1380, Val Loss=0.2415, Val Acc=0.9220\n",
            "Epoch 52/100: Train Loss=0.1438, Val Loss=0.2546, Val Acc=0.9260\n",
            "Epoch 53/100: Train Loss=0.1327, Val Loss=0.2308, Val Acc=0.9340\n",
            "Epoch 54/100: Train Loss=0.1294, Val Loss=0.2515, Val Acc=0.9290\n",
            "Epoch 55/100: Train Loss=0.1314, Val Loss=0.2383, Val Acc=0.9300\n",
            "Epoch 56/100: Train Loss=0.1264, Val Loss=0.2550, Val Acc=0.9290\n",
            "Epoch 57/100: Train Loss=0.1350, Val Loss=0.2312, Val Acc=0.9330\n",
            "Epoch 58/100: Train Loss=0.1239, Val Loss=0.2466, Val Acc=0.9270\n",
            "Epoch 59/100: Train Loss=0.1170, Val Loss=0.2442, Val Acc=0.9270\n",
            "Epoch 60/100: Train Loss=0.1304, Val Loss=0.2483, Val Acc=0.9320\n",
            "Epoch 61/100: Train Loss=0.1154, Val Loss=0.2366, Val Acc=0.9300\n",
            "Epoch 62/100: Train Loss=0.1300, Val Loss=0.2483, Val Acc=0.9290\n",
            "Epoch 63/100: Train Loss=0.1486, Val Loss=0.2285, Val Acc=0.9300\n",
            "Epoch 64/100: Train Loss=0.1223, Val Loss=0.2377, Val Acc=0.9290\n",
            "Epoch 65/100: Train Loss=0.1292, Val Loss=0.2315, Val Acc=0.9330\n",
            "Epoch 66/100: Train Loss=0.1210, Val Loss=0.2233, Val Acc=0.9330\n",
            "Epoch 67/100: Train Loss=0.1292, Val Loss=0.2411, Val Acc=0.9290\n",
            "Epoch 68/100: Train Loss=0.1133, Val Loss=0.2352, Val Acc=0.9310\n",
            "Epoch 69/100: Train Loss=0.1209, Val Loss=0.2432, Val Acc=0.9320\n",
            "Epoch 70/100: Train Loss=0.1140, Val Loss=0.2204, Val Acc=0.9350\n",
            "Epoch 71/100: Train Loss=0.1209, Val Loss=0.2274, Val Acc=0.9370\n",
            "Epoch 72/100: Train Loss=0.1214, Val Loss=0.2271, Val Acc=0.9280\n",
            "Epoch 73/100: Train Loss=0.1080, Val Loss=0.2339, Val Acc=0.9290\n",
            "Epoch 74/100: Train Loss=0.1274, Val Loss=0.2467, Val Acc=0.9260\n",
            "Epoch 75/100: Train Loss=0.1395, Val Loss=0.2235, Val Acc=0.9340\n",
            "Epoch 76/100: Train Loss=0.1245, Val Loss=0.2377, Val Acc=0.9240\n",
            "Epoch 77/100: Train Loss=0.1372, Val Loss=0.2337, Val Acc=0.9260\n",
            "Epoch 78/100: Train Loss=0.1232, Val Loss=0.2316, Val Acc=0.9320\n",
            "Epoch 79/100: Train Loss=0.1221, Val Loss=0.2200, Val Acc=0.9270\n",
            "Epoch 80/100: Train Loss=0.1217, Val Loss=0.2338, Val Acc=0.9350\n",
            "Epoch 81/100: Train Loss=0.1134, Val Loss=0.2280, Val Acc=0.9360\n",
            "Epoch 82/100: Train Loss=0.1269, Val Loss=0.2301, Val Acc=0.9300\n",
            "Epoch 83/100: Train Loss=0.1247, Val Loss=0.2334, Val Acc=0.9330\n",
            "Epoch 84/100: Train Loss=0.1192, Val Loss=0.2376, Val Acc=0.9310\n",
            "Epoch 85/100: Train Loss=0.1230, Val Loss=0.2332, Val Acc=0.9340\n",
            "Epoch 86/100: Train Loss=0.1101, Val Loss=0.2256, Val Acc=0.9340\n",
            "Epoch 87/100: Train Loss=0.1436, Val Loss=0.2228, Val Acc=0.9340\n",
            "Epoch 88/100: Train Loss=0.1345, Val Loss=0.2291, Val Acc=0.9300\n",
            "Epoch 89/100: Train Loss=0.1171, Val Loss=0.2445, Val Acc=0.9270\n",
            "Epoch 90/100: Train Loss=0.1152, Val Loss=0.2222, Val Acc=0.9330\n",
            "Epoch 91/100: Train Loss=0.1023, Val Loss=0.2334, Val Acc=0.9300\n",
            "Epoch 92/100: Train Loss=0.1067, Val Loss=0.2162, Val Acc=0.9330\n",
            "Epoch 93/100: Train Loss=0.1205, Val Loss=0.2265, Val Acc=0.9340\n",
            "Epoch 94/100: Train Loss=0.1205, Val Loss=0.2379, Val Acc=0.9310\n",
            "Epoch 95/100: Train Loss=0.1378, Val Loss=0.2259, Val Acc=0.9330\n",
            "Epoch 96/100: Train Loss=0.1447, Val Loss=0.2525, Val Acc=0.9310\n",
            "Epoch 97/100: Train Loss=0.1483, Val Loss=0.2305, Val Acc=0.9330\n",
            "Epoch 98/100: Train Loss=0.1228, Val Loss=0.2501, Val Acc=0.9250\n",
            "Epoch 99/100: Train Loss=0.1111, Val Loss=0.2217, Val Acc=0.9320\n",
            "Epoch 100/100: Train Loss=0.1179, Val Loss=0.2382, Val Acc=0.9280\n",
            "WD=0.001 -> Val Loss: 0.2162\n",
            "\n",
            "Running Experiment 2 with weight decay = 0.01\n",
            "Epoch 1/100: Train Loss=3.0171, Val Loss=2.2632, Val Acc=0.1110\n",
            "Epoch 2/100: Train Loss=1.6873, Val Loss=1.2903, Val Acc=0.6300\n",
            "Epoch 3/100: Train Loss=0.9929, Val Loss=0.7186, Val Acc=0.7820\n",
            "Epoch 4/100: Train Loss=0.6935, Val Loss=0.5328, Val Acc=0.8490\n",
            "Epoch 5/100: Train Loss=0.6537, Val Loss=0.5308, Val Acc=0.8690\n",
            "Epoch 6/100: Train Loss=0.6792, Val Loss=0.5555, Val Acc=0.8720\n",
            "Epoch 7/100: Train Loss=0.6379, Val Loss=0.5168, Val Acc=0.8680\n",
            "Epoch 8/100: Train Loss=0.6186, Val Loss=0.5636, Val Acc=0.8620\n",
            "Epoch 9/100: Train Loss=0.6011, Val Loss=0.5178, Val Acc=0.8670\n",
            "Epoch 10/100: Train Loss=0.5816, Val Loss=0.4649, Val Acc=0.9040\n",
            "Epoch 11/100: Train Loss=0.6121, Val Loss=0.5673, Val Acc=0.8360\n",
            "Epoch 12/100: Train Loss=0.6631, Val Loss=0.5456, Val Acc=0.8500\n",
            "Epoch 13/100: Train Loss=0.5879, Val Loss=0.5663, Val Acc=0.8410\n",
            "Epoch 14/100: Train Loss=0.5784, Val Loss=0.5156, Val Acc=0.8560\n",
            "Epoch 15/100: Train Loss=0.6287, Val Loss=0.5491, Val Acc=0.8550\n",
            "Epoch 16/100: Train Loss=0.5711, Val Loss=0.4830, Val Acc=0.8870\n",
            "Epoch 17/100: Train Loss=0.5728, Val Loss=0.5627, Val Acc=0.8390\n",
            "Epoch 18/100: Train Loss=0.6566, Val Loss=0.6324, Val Acc=0.8090\n",
            "Epoch 19/100: Train Loss=0.6396, Val Loss=0.5057, Val Acc=0.8760\n",
            "Epoch 20/100: Train Loss=0.5567, Val Loss=0.4642, Val Acc=0.8850\n",
            "Epoch 21/100: Train Loss=0.5375, Val Loss=0.5476, Val Acc=0.8530\n",
            "Epoch 22/100: Train Loss=0.6890, Val Loss=0.5427, Val Acc=0.8460\n",
            "Epoch 23/100: Train Loss=0.5809, Val Loss=0.5391, Val Acc=0.8600\n",
            "Epoch 24/100: Train Loss=0.5534, Val Loss=0.5370, Val Acc=0.8320\n",
            "Epoch 25/100: Train Loss=0.5917, Val Loss=0.4827, Val Acc=0.8770\n",
            "Epoch 26/100: Train Loss=0.5176, Val Loss=0.5753, Val Acc=0.8270\n",
            "Epoch 27/100: Train Loss=0.6075, Val Loss=0.4835, Val Acc=0.8920\n",
            "Epoch 28/100: Train Loss=0.6242, Val Loss=0.5414, Val Acc=0.8390\n",
            "Epoch 29/100: Train Loss=0.5780, Val Loss=0.5105, Val Acc=0.8740\n",
            "Epoch 30/100: Train Loss=0.5954, Val Loss=0.5069, Val Acc=0.8800\n",
            "Epoch 31/100: Train Loss=0.6395, Val Loss=0.5598, Val Acc=0.8190\n",
            "Epoch 32/100: Train Loss=0.5839, Val Loss=0.5054, Val Acc=0.8600\n",
            "Epoch 33/100: Train Loss=0.5588, Val Loss=0.5438, Val Acc=0.8440\n",
            "Epoch 34/100: Train Loss=0.6032, Val Loss=0.5683, Val Acc=0.8370\n",
            "Epoch 35/100: Train Loss=0.6561, Val Loss=0.5394, Val Acc=0.8320\n",
            "Epoch 36/100: Train Loss=0.5717, Val Loss=0.4882, Val Acc=0.8750\n",
            "Epoch 37/100: Train Loss=0.5520, Val Loss=0.5120, Val Acc=0.8630\n",
            "Epoch 38/100: Train Loss=0.6170, Val Loss=0.5066, Val Acc=0.8780\n",
            "Epoch 39/100: Train Loss=0.6104, Val Loss=0.5839, Val Acc=0.8260\n",
            "Epoch 40/100: Train Loss=0.5844, Val Loss=0.4836, Val Acc=0.8990\n",
            "Epoch 41/100: Train Loss=0.6047, Val Loss=0.5055, Val Acc=0.8530\n",
            "Epoch 42/100: Train Loss=0.6216, Val Loss=0.6150, Val Acc=0.8130\n",
            "Epoch 43/100: Train Loss=0.5767, Val Loss=0.5562, Val Acc=0.8570\n",
            "Epoch 44/100: Train Loss=0.5942, Val Loss=0.5095, Val Acc=0.8710\n",
            "Epoch 45/100: Train Loss=0.5934, Val Loss=0.5206, Val Acc=0.8660\n",
            "Epoch 46/100: Train Loss=0.6289, Val Loss=0.5078, Val Acc=0.8610\n",
            "Epoch 47/100: Train Loss=0.5799, Val Loss=0.5363, Val Acc=0.8650\n",
            "Epoch 48/100: Train Loss=0.5645, Val Loss=0.4868, Val Acc=0.8760\n",
            "Epoch 49/100: Train Loss=0.5731, Val Loss=0.4714, Val Acc=0.8990\n",
            "Epoch 50/100: Train Loss=0.5627, Val Loss=0.5156, Val Acc=0.8650\n",
            "Epoch 51/100: Train Loss=0.5832, Val Loss=0.5040, Val Acc=0.8810\n",
            "Epoch 52/100: Train Loss=0.5836, Val Loss=0.5507, Val Acc=0.8420\n",
            "Epoch 53/100: Train Loss=0.5500, Val Loss=0.5461, Val Acc=0.8530\n",
            "Epoch 54/100: Train Loss=0.5857, Val Loss=0.5068, Val Acc=0.8690\n",
            "Epoch 55/100: Train Loss=0.6051, Val Loss=0.4789, Val Acc=0.8770\n",
            "Epoch 56/100: Train Loss=0.5621, Val Loss=0.5261, Val Acc=0.8410\n",
            "Epoch 57/100: Train Loss=0.6038, Val Loss=0.5260, Val Acc=0.8460\n",
            "Epoch 58/100: Train Loss=0.5646, Val Loss=0.4897, Val Acc=0.8820\n",
            "Epoch 59/100: Train Loss=0.6132, Val Loss=0.5299, Val Acc=0.8480\n",
            "Epoch 60/100: Train Loss=0.6482, Val Loss=0.5897, Val Acc=0.8150\n",
            "Epoch 61/100: Train Loss=0.6075, Val Loss=0.6132, Val Acc=0.8200\n",
            "Epoch 62/100: Train Loss=0.6229, Val Loss=0.5098, Val Acc=0.8620\n",
            "Epoch 63/100: Train Loss=0.6163, Val Loss=0.5582, Val Acc=0.8240\n",
            "Epoch 64/100: Train Loss=0.6230, Val Loss=0.5774, Val Acc=0.8480\n",
            "Epoch 65/100: Train Loss=0.5967, Val Loss=0.5076, Val Acc=0.8770\n",
            "Epoch 66/100: Train Loss=0.5849, Val Loss=0.5014, Val Acc=0.8750\n",
            "Epoch 67/100: Train Loss=0.5554, Val Loss=0.5439, Val Acc=0.8400\n",
            "Epoch 68/100: Train Loss=0.6180, Val Loss=0.5810, Val Acc=0.8470\n",
            "Epoch 69/100: Train Loss=0.6169, Val Loss=0.6180, Val Acc=0.7980\n",
            "Epoch 70/100: Train Loss=0.6628, Val Loss=0.5695, Val Acc=0.8630\n",
            "Epoch 71/100: Train Loss=0.6036, Val Loss=0.4953, Val Acc=0.8660\n",
            "Epoch 72/100: Train Loss=0.5433, Val Loss=0.5836, Val Acc=0.8170\n",
            "Epoch 73/100: Train Loss=0.5934, Val Loss=0.5225, Val Acc=0.8700\n",
            "Epoch 74/100: Train Loss=0.5937, Val Loss=0.5875, Val Acc=0.8290\n",
            "Epoch 75/100: Train Loss=0.6513, Val Loss=0.5380, Val Acc=0.8500\n",
            "Epoch 76/100: Train Loss=0.5731, Val Loss=0.5696, Val Acc=0.8220\n",
            "Epoch 77/100: Train Loss=0.5820, Val Loss=0.5305, Val Acc=0.8490\n",
            "Epoch 78/100: Train Loss=0.5840, Val Loss=0.5496, Val Acc=0.8510\n",
            "Epoch 79/100: Train Loss=0.5740, Val Loss=0.5513, Val Acc=0.8240\n",
            "Epoch 80/100: Train Loss=0.6320, Val Loss=0.5706, Val Acc=0.8280\n",
            "Epoch 81/100: Train Loss=0.5693, Val Loss=0.5107, Val Acc=0.8540\n",
            "Epoch 82/100: Train Loss=0.5551, Val Loss=0.4667, Val Acc=0.8890\n",
            "Epoch 83/100: Train Loss=0.5948, Val Loss=0.5379, Val Acc=0.8590\n",
            "Epoch 84/100: Train Loss=0.5938, Val Loss=0.5156, Val Acc=0.8730\n",
            "Epoch 85/100: Train Loss=0.5549, Val Loss=0.5314, Val Acc=0.8460\n",
            "Epoch 86/100: Train Loss=0.6052, Val Loss=0.5050, Val Acc=0.8660\n",
            "Epoch 87/100: Train Loss=0.6178, Val Loss=0.5324, Val Acc=0.8450\n",
            "Epoch 88/100: Train Loss=0.5734, Val Loss=0.5249, Val Acc=0.8490\n",
            "Epoch 89/100: Train Loss=0.5729, Val Loss=0.5055, Val Acc=0.8570\n",
            "Epoch 90/100: Train Loss=0.5911, Val Loss=0.5499, Val Acc=0.8300\n",
            "Epoch 91/100: Train Loss=0.6030, Val Loss=0.6429, Val Acc=0.7980\n",
            "Epoch 92/100: Train Loss=0.6661, Val Loss=0.5017, Val Acc=0.8740\n",
            "Epoch 93/100: Train Loss=0.6359, Val Loss=0.5047, Val Acc=0.8780\n",
            "Epoch 94/100: Train Loss=0.5706, Val Loss=0.4707, Val Acc=0.9030\n",
            "Epoch 95/100: Train Loss=0.5583, Val Loss=0.5362, Val Acc=0.8490\n",
            "Epoch 96/100: Train Loss=0.6164, Val Loss=0.5142, Val Acc=0.8840\n",
            "Epoch 97/100: Train Loss=0.6132, Val Loss=0.5049, Val Acc=0.8830\n",
            "Epoch 98/100: Train Loss=0.5671, Val Loss=0.4923, Val Acc=0.8660\n",
            "Epoch 99/100: Train Loss=0.5445, Val Loss=0.4831, Val Acc=0.8660\n",
            "Epoch 100/100: Train Loss=0.5697, Val Loss=0.5372, Val Acc=0.8640\n",
            "WD=0.01 -> Val Loss: 0.4642\n",
            "\n",
            "Running Experiment 2 with weight decay = 1\n",
            "Epoch 1/100: Train Loss=3.2700, Val Loss=4.7099, Val Acc=0.1000\n",
            "Epoch 2/100: Train Loss=5.4987, Val Loss=7.6299, Val Acc=0.0780\n",
            "Epoch 3/100: Train Loss=7.4571, Val Loss=6.8054, Val Acc=0.1770\n",
            "Epoch 4/100: Train Loss=8.6253, Val Loss=6.7939, Val Acc=0.0780\n",
            "Epoch 5/100: Train Loss=7.8277, Val Loss=6.1082, Val Acc=0.1340\n",
            "Epoch 6/100: Train Loss=6.9706, Val Loss=6.3818, Val Acc=0.0910\n",
            "Epoch 7/100: Train Loss=6.9631, Val Loss=8.8243, Val Acc=0.0870\n",
            "Epoch 8/100: Train Loss=6.9221, Val Loss=9.2040, Val Acc=0.0960\n",
            "Epoch 9/100: Train Loss=7.2636, Val Loss=9.9813, Val Acc=0.1340\n",
            "Epoch 10/100: Train Loss=6.8793, Val Loss=9.8997, Val Acc=0.1770\n",
            "Epoch 11/100: Train Loss=7.8801, Val Loss=7.5751, Val Acc=0.0960\n",
            "Epoch 12/100: Train Loss=7.0837, Val Loss=6.6768, Val Acc=0.1340\n",
            "Epoch 13/100: Train Loss=7.0657, Val Loss=5.0075, Val Acc=0.1770\n",
            "Epoch 14/100: Train Loss=6.4275, Val Loss=7.9843, Val Acc=0.0960\n",
            "Epoch 15/100: Train Loss=7.3025, Val Loss=6.3514, Val Acc=0.0870\n",
            "Epoch 16/100: Train Loss=6.7190, Val Loss=11.1922, Val Acc=0.1340\n",
            "Epoch 17/100: Train Loss=7.6663, Val Loss=6.2876, Val Acc=0.0960\n",
            "Epoch 18/100: Train Loss=7.6543, Val Loss=5.9311, Val Acc=0.0870\n",
            "Epoch 19/100: Train Loss=6.9430, Val Loss=9.2862, Val Acc=0.1340\n",
            "Epoch 20/100: Train Loss=7.4827, Val Loss=7.3397, Val Acc=0.0960\n",
            "Epoch 21/100: Train Loss=7.7398, Val Loss=5.7621, Val Acc=0.0870\n",
            "Epoch 22/100: Train Loss=7.4944, Val Loss=7.1833, Val Acc=0.1340\n",
            "Epoch 23/100: Train Loss=7.1949, Val Loss=6.2967, Val Acc=0.0960\n",
            "Epoch 24/100: Train Loss=7.7859, Val Loss=6.6315, Val Acc=0.0870\n",
            "Epoch 25/100: Train Loss=6.9206, Val Loss=8.1498, Val Acc=0.1340\n",
            "Epoch 26/100: Train Loss=7.1755, Val Loss=6.7822, Val Acc=0.0960\n",
            "Epoch 27/100: Train Loss=7.4262, Val Loss=5.9484, Val Acc=0.0770\n",
            "Epoch 28/100: Train Loss=7.1659, Val Loss=7.2620, Val Acc=0.1340\n",
            "Epoch 29/100: Train Loss=6.7799, Val Loss=9.6872, Val Acc=0.0960\n",
            "Epoch 30/100: Train Loss=8.2820, Val Loss=5.6132, Val Acc=0.0780\n",
            "Epoch 31/100: Train Loss=6.7891, Val Loss=10.6130, Val Acc=0.1340\n",
            "Epoch 32/100: Train Loss=7.7144, Val Loss=7.2806, Val Acc=0.0960\n",
            "Epoch 33/100: Train Loss=7.5036, Val Loss=7.8839, Val Acc=0.0780\n",
            "Epoch 34/100: Train Loss=7.3867, Val Loss=10.0471, Val Acc=0.1340\n",
            "Epoch 35/100: Train Loss=7.4209, Val Loss=7.8745, Val Acc=0.0960\n",
            "Epoch 36/100: Train Loss=8.0225, Val Loss=6.0458, Val Acc=0.0780\n",
            "Epoch 37/100: Train Loss=7.2174, Val Loss=8.2646, Val Acc=0.1340\n",
            "Epoch 38/100: Train Loss=7.4271, Val Loss=4.8898, Val Acc=0.0960\n",
            "Epoch 39/100: Train Loss=7.1899, Val Loss=6.7970, Val Acc=0.1000\n",
            "Epoch 40/100: Train Loss=7.0313, Val Loss=8.0397, Val Acc=0.1340\n",
            "Epoch 41/100: Train Loss=6.3356, Val Loss=6.2711, Val Acc=0.0910\n",
            "Epoch 42/100: Train Loss=7.1613, Val Loss=9.5841, Val Acc=0.0870\n",
            "Epoch 43/100: Train Loss=7.0077, Val Loss=7.3902, Val Acc=0.0960\n",
            "Epoch 44/100: Train Loss=7.4684, Val Loss=8.0270, Val Acc=0.1000\n",
            "Epoch 45/100: Train Loss=7.2692, Val Loss=6.3535, Val Acc=0.1340\n",
            "Epoch 46/100: Train Loss=6.4117, Val Loss=5.7478, Val Acc=0.0840\n",
            "Epoch 47/100: Train Loss=6.0557, Val Loss=9.1368, Val Acc=0.0870\n",
            "Epoch 48/100: Train Loss=7.6700, Val Loss=4.9697, Val Acc=0.1770\n",
            "Epoch 49/100: Train Loss=5.9954, Val Loss=7.2791, Val Acc=0.1340\n",
            "Epoch 50/100: Train Loss=6.6992, Val Loss=9.7192, Val Acc=0.0870\n",
            "Epoch 51/100: Train Loss=7.9692, Val Loss=7.0446, Val Acc=0.1000\n",
            "Epoch 52/100: Train Loss=6.4709, Val Loss=5.1848, Val Acc=0.1770\n",
            "Epoch 53/100: Train Loss=6.5862, Val Loss=7.9223, Val Acc=0.0850\n",
            "Epoch 54/100: Train Loss=6.8755, Val Loss=6.1852, Val Acc=0.1340\n",
            "Epoch 55/100: Train Loss=7.4154, Val Loss=9.0849, Val Acc=0.0960\n",
            "Epoch 56/100: Train Loss=6.9973, Val Loss=6.4739, Val Acc=0.1000\n",
            "Epoch 57/100: Train Loss=6.8437, Val Loss=7.2434, Val Acc=0.1340\n",
            "Epoch 58/100: Train Loss=7.1498, Val Loss=7.2177, Val Acc=0.1770\n",
            "Epoch 59/100: Train Loss=7.6284, Val Loss=6.4978, Val Acc=0.1000\n",
            "Epoch 60/100: Train Loss=7.0113, Val Loss=9.2963, Val Acc=0.1340\n",
            "Epoch 61/100: Train Loss=6.9452, Val Loss=6.5134, Val Acc=0.0850\n",
            "Epoch 62/100: Train Loss=6.9898, Val Loss=6.7565, Val Acc=0.0770\n",
            "Epoch 63/100: Train Loss=7.2948, Val Loss=8.9113, Val Acc=0.0960\n",
            "Epoch 64/100: Train Loss=8.1674, Val Loss=6.1493, Val Acc=0.1000\n",
            "Epoch 65/100: Train Loss=6.0293, Val Loss=6.5229, Val Acc=0.1770\n",
            "Epoch 66/100: Train Loss=6.9273, Val Loss=8.1553, Val Acc=0.0960\n",
            "Epoch 67/100: Train Loss=5.9523, Val Loss=3.6687, Val Acc=0.0770\n",
            "Epoch 68/100: Train Loss=7.0748, Val Loss=10.2032, Val Acc=0.1340\n",
            "Epoch 69/100: Train Loss=7.6243, Val Loss=5.7003, Val Acc=0.0750\n",
            "Epoch 70/100: Train Loss=7.6230, Val Loss=7.0034, Val Acc=0.0870\n",
            "Epoch 71/100: Train Loss=7.5905, Val Loss=7.3767, Val Acc=0.1340\n",
            "Epoch 72/100: Train Loss=6.9476, Val Loss=6.7414, Val Acc=0.0850\n",
            "Epoch 73/100: Train Loss=7.3901, Val Loss=5.6896, Val Acc=0.0910\n",
            "Epoch 74/100: Train Loss=7.0792, Val Loss=8.8400, Val Acc=0.1340\n",
            "Epoch 75/100: Train Loss=7.5533, Val Loss=4.6481, Val Acc=0.0770\n",
            "Epoch 76/100: Train Loss=7.3535, Val Loss=6.9638, Val Acc=0.0960\n",
            "Epoch 77/100: Train Loss=7.1818, Val Loss=11.4526, Val Acc=0.1340\n",
            "Epoch 78/100: Train Loss=8.1024, Val Loss=5.5301, Val Acc=0.1770\n",
            "Epoch 79/100: Train Loss=6.6647, Val Loss=9.6988, Val Acc=0.0960\n",
            "Epoch 80/100: Train Loss=6.6088, Val Loss=6.8416, Val Acc=0.0780\n",
            "Epoch 81/100: Train Loss=7.4565, Val Loss=4.8199, Val Acc=0.0990\n",
            "Epoch 82/100: Train Loss=6.0528, Val Loss=5.2069, Val Acc=0.0960\n",
            "Epoch 83/100: Train Loss=5.3083, Val Loss=6.0500, Val Acc=0.0780\n",
            "Epoch 84/100: Train Loss=7.1210, Val Loss=6.3072, Val Acc=0.0750\n",
            "Epoch 85/100: Train Loss=7.7532, Val Loss=10.4311, Val Acc=0.1340\n",
            "Epoch 86/100: Train Loss=7.0880, Val Loss=7.5906, Val Acc=0.1770\n",
            "Epoch 87/100: Train Loss=7.2479, Val Loss=6.5423, Val Acc=0.0780\n",
            "Epoch 88/100: Train Loss=6.9518, Val Loss=8.8664, Val Acc=0.1340\n",
            "Epoch 89/100: Train Loss=7.3164, Val Loss=7.0321, Val Acc=0.1770\n",
            "Epoch 90/100: Train Loss=6.3972, Val Loss=8.9494, Val Acc=0.0780\n",
            "Epoch 91/100: Train Loss=6.6135, Val Loss=8.5005, Val Acc=0.1000\n",
            "Epoch 92/100: Train Loss=7.2744, Val Loss=8.0449, Val Acc=0.1340\n",
            "Epoch 93/100: Train Loss=7.1906, Val Loss=4.6331, Val Acc=0.0850\n",
            "Epoch 94/100: Train Loss=7.4146, Val Loss=4.3882, Val Acc=0.0750\n",
            "Epoch 95/100: Train Loss=6.8024, Val Loss=6.3845, Val Acc=0.1340\n",
            "Epoch 96/100: Train Loss=6.9964, Val Loss=6.5180, Val Acc=0.0850\n",
            "Epoch 97/100: Train Loss=7.2221, Val Loss=6.4900, Val Acc=0.1000\n",
            "Epoch 98/100: Train Loss=6.4623, Val Loss=6.2485, Val Acc=0.1770\n",
            "Epoch 99/100: Train Loss=7.0188, Val Loss=7.5761, Val Acc=0.1340\n",
            "Epoch 100/100: Train Loss=7.0150, Val Loss=7.0037, Val Acc=0.1000\n",
            "WD=1 -> Val Loss: 3.6687\n",
            "\n",
            "Running Experiment 2 with weight decay = 2\n",
            "Epoch 1/100: Train Loss=3.6263, Val Loss=4.7980, Val Acc=0.0780\n",
            "Epoch 2/100: Train Loss=7.6584, Val Loss=6.5331, Val Acc=0.1340\n",
            "Epoch 3/100: Train Loss=6.9524, Val Loss=8.4966, Val Acc=0.1340\n",
            "Epoch 4/100: Train Loss=8.6258, Val Loss=6.7259, Val Acc=0.0850\n",
            "Epoch 5/100: Train Loss=11.4393, Val Loss=5.9402, Val Acc=0.1770\n",
            "Epoch 6/100: Train Loss=9.8771, Val Loss=12.6286, Val Acc=0.1770\n",
            "Epoch 7/100: Train Loss=11.7819, Val Loss=10.0766, Val Acc=0.1770\n",
            "Epoch 8/100: Train Loss=11.0660, Val Loss=12.4361, Val Acc=0.1770\n",
            "Epoch 9/100: Train Loss=11.7444, Val Loss=11.2561, Val Acc=0.1770\n",
            "Epoch 10/100: Train Loss=11.2807, Val Loss=10.6468, Val Acc=0.1770\n",
            "Epoch 11/100: Train Loss=11.1125, Val Loss=10.4248, Val Acc=0.1770\n",
            "Epoch 12/100: Train Loss=11.0971, Val Loss=10.1919, Val Acc=0.1770\n",
            "Epoch 13/100: Train Loss=10.4698, Val Loss=11.4266, Val Acc=0.1770\n",
            "Epoch 14/100: Train Loss=12.1259, Val Loss=10.6259, Val Acc=0.1770\n",
            "Epoch 15/100: Train Loss=11.1368, Val Loss=9.1153, Val Acc=0.1770\n",
            "Epoch 16/100: Train Loss=11.2424, Val Loss=11.0583, Val Acc=0.1770\n",
            "Epoch 17/100: Train Loss=10.9832, Val Loss=10.9133, Val Acc=0.1770\n",
            "Epoch 18/100: Train Loss=11.2896, Val Loss=9.9158, Val Acc=0.1770\n",
            "Epoch 19/100: Train Loss=10.9440, Val Loss=11.1805, Val Acc=0.1770\n",
            "Epoch 20/100: Train Loss=10.8539, Val Loss=9.0814, Val Acc=0.1770\n",
            "Epoch 21/100: Train Loss=10.6293, Val Loss=12.1689, Val Acc=0.1770\n",
            "Epoch 22/100: Train Loss=11.4617, Val Loss=9.4466, Val Acc=0.1770\n",
            "Epoch 23/100: Train Loss=11.4441, Val Loss=9.9596, Val Acc=0.1770\n",
            "Epoch 24/100: Train Loss=9.9238, Val Loss=12.2627, Val Acc=0.1770\n",
            "Epoch 25/100: Train Loss=11.6862, Val Loss=8.9520, Val Acc=0.1770\n",
            "Epoch 26/100: Train Loss=11.0979, Val Loss=10.5564, Val Acc=0.1770\n",
            "Epoch 27/100: Train Loss=10.5543, Val Loss=11.4136, Val Acc=0.1770\n",
            "Epoch 28/100: Train Loss=10.7419, Val Loss=11.1373, Val Acc=0.1770\n",
            "Epoch 29/100: Train Loss=11.0144, Val Loss=11.6877, Val Acc=0.1770\n",
            "Epoch 30/100: Train Loss=11.6991, Val Loss=10.3701, Val Acc=0.1770\n",
            "Epoch 31/100: Train Loss=10.8519, Val Loss=11.4942, Val Acc=0.1770\n",
            "Epoch 32/100: Train Loss=11.4537, Val Loss=8.6642, Val Acc=0.1770\n",
            "Epoch 33/100: Train Loss=10.7768, Val Loss=10.5716, Val Acc=0.1770\n",
            "Epoch 34/100: Train Loss=11.4677, Val Loss=11.2837, Val Acc=0.1770\n",
            "Epoch 35/100: Train Loss=11.2057, Val Loss=9.6754, Val Acc=0.1770\n",
            "Epoch 36/100: Train Loss=11.2015, Val Loss=10.0637, Val Acc=0.1770\n",
            "Epoch 37/100: Train Loss=10.9175, Val Loss=13.8539, Val Acc=0.1770\n",
            "Epoch 38/100: Train Loss=11.3380, Val Loss=9.0887, Val Acc=0.1770\n",
            "Epoch 39/100: Train Loss=11.2445, Val Loss=10.8065, Val Acc=0.1770\n",
            "Epoch 40/100: Train Loss=10.8717, Val Loss=10.8154, Val Acc=0.1770\n",
            "Epoch 41/100: Train Loss=11.2999, Val Loss=11.5423, Val Acc=0.1770\n",
            "Epoch 42/100: Train Loss=10.9519, Val Loss=10.8526, Val Acc=0.1770\n",
            "Epoch 43/100: Train Loss=11.5622, Val Loss=9.8499, Val Acc=0.1770\n",
            "Epoch 44/100: Train Loss=10.8753, Val Loss=10.8741, Val Acc=0.1770\n",
            "Epoch 45/100: Train Loss=11.5971, Val Loss=9.4086, Val Acc=0.1770\n",
            "Epoch 46/100: Train Loss=11.4897, Val Loss=10.4810, Val Acc=0.1770\n",
            "Epoch 47/100: Train Loss=10.7826, Val Loss=10.1925, Val Acc=0.1770\n",
            "Epoch 48/100: Train Loss=11.5997, Val Loss=10.2687, Val Acc=0.1770\n",
            "Epoch 49/100: Train Loss=10.7100, Val Loss=11.1058, Val Acc=0.1770\n",
            "Epoch 50/100: Train Loss=11.2969, Val Loss=9.8040, Val Acc=0.1770\n",
            "Epoch 51/100: Train Loss=11.0853, Val Loss=10.5360, Val Acc=0.1770\n",
            "Epoch 52/100: Train Loss=11.1639, Val Loss=10.6483, Val Acc=0.1770\n",
            "Epoch 53/100: Train Loss=11.4659, Val Loss=8.5191, Val Acc=0.1770\n",
            "Epoch 54/100: Train Loss=11.0110, Val Loss=10.6451, Val Acc=0.1770\n",
            "Epoch 55/100: Train Loss=11.4892, Val Loss=12.5307, Val Acc=0.1770\n",
            "Epoch 56/100: Train Loss=10.5151, Val Loss=11.2487, Val Acc=0.1770\n",
            "Epoch 57/100: Train Loss=10.9827, Val Loss=10.7263, Val Acc=0.1770\n",
            "Epoch 58/100: Train Loss=11.7493, Val Loss=9.7559, Val Acc=0.1770\n",
            "Epoch 59/100: Train Loss=11.1454, Val Loss=12.7399, Val Acc=0.1770\n",
            "Epoch 60/100: Train Loss=11.9835, Val Loss=9.3238, Val Acc=0.1770\n",
            "Epoch 61/100: Train Loss=10.6610, Val Loss=11.0541, Val Acc=0.1770\n",
            "Epoch 62/100: Train Loss=11.2433, Val Loss=10.1973, Val Acc=0.1770\n",
            "Epoch 63/100: Train Loss=11.3187, Val Loss=10.6147, Val Acc=0.1770\n",
            "Epoch 64/100: Train Loss=10.6736, Val Loss=8.9998, Val Acc=0.1770\n",
            "Epoch 65/100: Train Loss=11.3850, Val Loss=14.4326, Val Acc=0.1770\n",
            "Epoch 66/100: Train Loss=11.2918, Val Loss=10.0720, Val Acc=0.1770\n",
            "Epoch 67/100: Train Loss=10.8411, Val Loss=10.8965, Val Acc=0.1770\n",
            "Epoch 68/100: Train Loss=10.5681, Val Loss=10.9464, Val Acc=0.1770\n",
            "Epoch 69/100: Train Loss=10.9242, Val Loss=11.8620, Val Acc=0.1770\n",
            "Epoch 70/100: Train Loss=11.1895, Val Loss=11.8937, Val Acc=0.1770\n",
            "Epoch 71/100: Train Loss=10.6343, Val Loss=9.8087, Val Acc=0.1770\n",
            "Epoch 72/100: Train Loss=11.2978, Val Loss=10.5473, Val Acc=0.1770\n",
            "Epoch 73/100: Train Loss=11.4161, Val Loss=9.5857, Val Acc=0.1770\n",
            "Epoch 74/100: Train Loss=11.2385, Val Loss=9.1637, Val Acc=0.1770\n",
            "Epoch 75/100: Train Loss=10.9939, Val Loss=10.9549, Val Acc=0.1770\n",
            "Epoch 76/100: Train Loss=10.7319, Val Loss=10.3847, Val Acc=0.1770\n",
            "Epoch 77/100: Train Loss=11.2070, Val Loss=10.3436, Val Acc=0.1770\n",
            "Epoch 78/100: Train Loss=11.1095, Val Loss=8.5243, Val Acc=0.1770\n",
            "Epoch 79/100: Train Loss=10.0769, Val Loss=12.5711, Val Acc=0.1770\n",
            "Epoch 80/100: Train Loss=10.7898, Val Loss=9.5481, Val Acc=0.1770\n",
            "Epoch 81/100: Train Loss=10.8689, Val Loss=10.7766, Val Acc=0.1770\n",
            "Epoch 82/100: Train Loss=11.2713, Val Loss=12.5666, Val Acc=0.1770\n",
            "Epoch 83/100: Train Loss=11.6281, Val Loss=8.5103, Val Acc=0.1770\n",
            "Epoch 84/100: Train Loss=10.4316, Val Loss=11.3649, Val Acc=0.1770\n",
            "Epoch 85/100: Train Loss=11.2853, Val Loss=11.2088, Val Acc=0.1770\n",
            "Epoch 86/100: Train Loss=11.1559, Val Loss=8.7488, Val Acc=0.1770\n",
            "Epoch 87/100: Train Loss=10.9315, Val Loss=11.7734, Val Acc=0.1770\n",
            "Epoch 88/100: Train Loss=11.2554, Val Loss=10.5104, Val Acc=0.1770\n",
            "Epoch 89/100: Train Loss=11.0395, Val Loss=10.1917, Val Acc=0.1770\n",
            "Epoch 90/100: Train Loss=10.5398, Val Loss=12.2761, Val Acc=0.1770\n",
            "Epoch 91/100: Train Loss=11.0611, Val Loss=8.8626, Val Acc=0.1770\n",
            "Epoch 92/100: Train Loss=11.5617, Val Loss=10.1941, Val Acc=0.1770\n",
            "Epoch 93/100: Train Loss=11.1104, Val Loss=11.5760, Val Acc=0.1770\n",
            "Epoch 94/100: Train Loss=10.1230, Val Loss=9.6932, Val Acc=0.1770\n",
            "Epoch 95/100: Train Loss=11.0317, Val Loss=11.4079, Val Acc=0.1770\n",
            "Epoch 96/100: Train Loss=11.3873, Val Loss=9.7761, Val Acc=0.1770\n",
            "Epoch 97/100: Train Loss=11.2601, Val Loss=11.7936, Val Acc=0.1770\n",
            "Epoch 98/100: Train Loss=10.4247, Val Loss=10.3879, Val Acc=0.1770\n",
            "Epoch 99/100: Train Loss=11.1231, Val Loss=11.9503, Val Acc=0.1770\n",
            "Epoch 100/100: Train Loss=10.6821, Val Loss=11.0877, Val Acc=0.1770\n",
            "WD=2 -> Val Loss: 4.7980\n",
            "\n",
            "Running Experiment 2 with weight decay = 5\n",
            "Epoch 1/100: Train Loss=6.5096, Val Loss=15.5503, Val Acc=0.1340\n",
            "Epoch 2/100: Train Loss=12.2472, Val Loss=9.9693, Val Acc=0.1770\n",
            "Epoch 3/100: Train Loss=12.4709, Val Loss=14.3312, Val Acc=0.0780\n",
            "Epoch 4/100: Train Loss=12.3729, Val Loss=11.4222, Val Acc=0.1340\n",
            "Epoch 5/100: Train Loss=12.4314, Val Loss=11.1318, Val Acc=0.1770\n",
            "Epoch 6/100: Train Loss=11.8523, Val Loss=13.5180, Val Acc=0.0780\n",
            "Epoch 7/100: Train Loss=11.5276, Val Loss=11.8170, Val Acc=0.1340\n",
            "Epoch 8/100: Train Loss=12.6868, Val Loss=8.6354, Val Acc=0.1770\n",
            "Epoch 9/100: Train Loss=12.6098, Val Loss=13.2452, Val Acc=0.0780\n",
            "Epoch 10/100: Train Loss=11.0342, Val Loss=11.4959, Val Acc=0.1340\n",
            "Epoch 11/100: Train Loss=12.0591, Val Loss=11.0368, Val Acc=0.1770\n",
            "Epoch 12/100: Train Loss=11.8315, Val Loss=14.7526, Val Acc=0.0780\n",
            "Epoch 13/100: Train Loss=11.5442, Val Loss=13.5580, Val Acc=0.1340\n",
            "Epoch 14/100: Train Loss=11.8421, Val Loss=12.0217, Val Acc=0.1770\n",
            "Epoch 15/100: Train Loss=12.9783, Val Loss=17.1485, Val Acc=0.0780\n",
            "Epoch 16/100: Train Loss=12.1598, Val Loss=15.8199, Val Acc=0.1340\n",
            "Epoch 17/100: Train Loss=12.1298, Val Loss=11.8125, Val Acc=0.1770\n",
            "Epoch 18/100: Train Loss=13.2125, Val Loss=11.6619, Val Acc=0.0780\n",
            "Epoch 19/100: Train Loss=11.4141, Val Loss=14.1750, Val Acc=0.1340\n",
            "Epoch 20/100: Train Loss=11.7391, Val Loss=13.5279, Val Acc=0.1770\n",
            "Epoch 21/100: Train Loss=11.4941, Val Loss=15.8100, Val Acc=0.0780\n",
            "Epoch 22/100: Train Loss=12.5363, Val Loss=15.4694, Val Acc=0.1340\n",
            "Epoch 23/100: Train Loss=11.8062, Val Loss=11.8426, Val Acc=0.1770\n",
            "Epoch 24/100: Train Loss=12.2208, Val Loss=13.8031, Val Acc=0.0780\n",
            "Epoch 25/100: Train Loss=12.3909, Val Loss=14.4743, Val Acc=0.1340\n",
            "Epoch 26/100: Train Loss=11.6311, Val Loss=10.7167, Val Acc=0.1770\n",
            "Epoch 27/100: Train Loss=12.0871, Val Loss=11.5563, Val Acc=0.0780\n",
            "Epoch 28/100: Train Loss=12.5807, Val Loss=12.0281, Val Acc=0.1340\n",
            "Epoch 29/100: Train Loss=11.3992, Val Loss=14.6776, Val Acc=0.1770\n",
            "Epoch 30/100: Train Loss=11.9455, Val Loss=14.0587, Val Acc=0.0780\n",
            "Epoch 31/100: Train Loss=12.2127, Val Loss=12.7672, Val Acc=0.1340\n",
            "Epoch 32/100: Train Loss=12.8467, Val Loss=12.2031, Val Acc=0.1770\n",
            "Epoch 33/100: Train Loss=11.7079, Val Loss=13.4514, Val Acc=0.0780\n",
            "Epoch 34/100: Train Loss=12.7506, Val Loss=12.2184, Val Acc=0.1340\n",
            "Epoch 35/100: Train Loss=12.5610, Val Loss=9.7611, Val Acc=0.1770\n",
            "Epoch 36/100: Train Loss=11.4314, Val Loss=15.2202, Val Acc=0.0780\n",
            "Epoch 37/100: Train Loss=12.0877, Val Loss=13.5874, Val Acc=0.1340\n",
            "Epoch 38/100: Train Loss=12.5067, Val Loss=11.1685, Val Acc=0.1770\n",
            "Epoch 39/100: Train Loss=12.2795, Val Loss=11.4512, Val Acc=0.0780\n",
            "Epoch 40/100: Train Loss=12.6168, Val Loss=11.2999, Val Acc=0.1340\n",
            "Epoch 41/100: Train Loss=12.2956, Val Loss=11.4778, Val Acc=0.1770\n",
            "Epoch 42/100: Train Loss=11.8378, Val Loss=11.8431, Val Acc=0.0780\n",
            "Epoch 43/100: Train Loss=12.3810, Val Loss=10.5452, Val Acc=0.1340\n",
            "Epoch 44/100: Train Loss=11.8418, Val Loss=11.6977, Val Acc=0.1770\n",
            "Epoch 45/100: Train Loss=12.4014, Val Loss=13.0892, Val Acc=0.0780\n",
            "Epoch 46/100: Train Loss=12.0553, Val Loss=11.7054, Val Acc=0.1340\n",
            "Epoch 47/100: Train Loss=12.4318, Val Loss=10.1530, Val Acc=0.1770\n",
            "Epoch 48/100: Train Loss=11.4589, Val Loss=13.1580, Val Acc=0.0780\n",
            "Epoch 49/100: Train Loss=13.1784, Val Loss=9.9743, Val Acc=0.1340\n",
            "Epoch 50/100: Train Loss=11.7183, Val Loss=9.9540, Val Acc=0.1770\n",
            "Epoch 51/100: Train Loss=12.1392, Val Loss=13.1458, Val Acc=0.0780\n",
            "Epoch 52/100: Train Loss=12.5557, Val Loss=11.0377, Val Acc=0.1340\n",
            "Epoch 53/100: Train Loss=12.5930, Val Loss=10.8315, Val Acc=0.1770\n",
            "Epoch 54/100: Train Loss=11.8069, Val Loss=14.3262, Val Acc=0.0780\n",
            "Epoch 55/100: Train Loss=11.7913, Val Loss=12.2497, Val Acc=0.1340\n",
            "Epoch 56/100: Train Loss=12.6259, Val Loss=10.6645, Val Acc=0.1770\n",
            "Epoch 57/100: Train Loss=11.8630, Val Loss=13.7698, Val Acc=0.0780\n",
            "Epoch 58/100: Train Loss=12.1556, Val Loss=11.8776, Val Acc=0.1340\n",
            "Epoch 59/100: Train Loss=12.7093, Val Loss=12.8283, Val Acc=0.1770\n",
            "Epoch 60/100: Train Loss=11.6807, Val Loss=13.4963, Val Acc=0.0780\n",
            "Epoch 61/100: Train Loss=12.2103, Val Loss=10.0744, Val Acc=0.1340\n",
            "Epoch 62/100: Train Loss=11.8932, Val Loss=11.0096, Val Acc=0.1770\n",
            "Epoch 63/100: Train Loss=12.2306, Val Loss=13.4596, Val Acc=0.0780\n",
            "Epoch 64/100: Train Loss=12.7954, Val Loss=14.4749, Val Acc=0.1340\n",
            "Epoch 65/100: Train Loss=11.8578, Val Loss=12.7709, Val Acc=0.1770\n",
            "Epoch 66/100: Train Loss=12.7610, Val Loss=10.7835, Val Acc=0.0780\n",
            "Epoch 67/100: Train Loss=11.6663, Val Loss=11.3552, Val Acc=0.1340\n",
            "Epoch 68/100: Train Loss=11.6834, Val Loss=10.3816, Val Acc=0.1770\n",
            "Epoch 69/100: Train Loss=12.4977, Val Loss=12.7369, Val Acc=0.0780\n",
            "Epoch 70/100: Train Loss=12.5284, Val Loss=11.7691, Val Acc=0.1340\n",
            "Epoch 71/100: Train Loss=12.1790, Val Loss=10.7159, Val Acc=0.1770\n",
            "Epoch 72/100: Train Loss=12.4386, Val Loss=12.2279, Val Acc=0.0780\n",
            "Epoch 73/100: Train Loss=11.7865, Val Loss=11.6827, Val Acc=0.1340\n",
            "Epoch 74/100: Train Loss=12.7593, Val Loss=9.1372, Val Acc=0.1770\n",
            "Epoch 75/100: Train Loss=12.0030, Val Loss=11.7025, Val Acc=0.0780\n",
            "Epoch 76/100: Train Loss=12.4461, Val Loss=13.3459, Val Acc=0.1340\n",
            "Epoch 77/100: Train Loss=12.1515, Val Loss=12.7968, Val Acc=0.1770\n",
            "Epoch 78/100: Train Loss=12.0371, Val Loss=13.8104, Val Acc=0.0780\n",
            "Epoch 79/100: Train Loss=12.2770, Val Loss=11.5331, Val Acc=0.1340\n",
            "Epoch 80/100: Train Loss=12.1292, Val Loss=11.7100, Val Acc=0.1770\n",
            "Epoch 81/100: Train Loss=12.9276, Val Loss=11.3646, Val Acc=0.0780\n",
            "Epoch 82/100: Train Loss=12.1040, Val Loss=11.2554, Val Acc=0.1340\n",
            "Epoch 83/100: Train Loss=11.3808, Val Loss=10.3948, Val Acc=0.1770\n",
            "Epoch 84/100: Train Loss=12.4513, Val Loss=11.1634, Val Acc=0.0780\n",
            "Epoch 85/100: Train Loss=12.0773, Val Loss=10.1272, Val Acc=0.1340\n",
            "Epoch 86/100: Train Loss=11.9470, Val Loss=11.3649, Val Acc=0.1770\n",
            "Epoch 87/100: Train Loss=12.1820, Val Loss=12.6127, Val Acc=0.0780\n",
            "Epoch 88/100: Train Loss=13.2261, Val Loss=11.3341, Val Acc=0.1340\n",
            "Epoch 89/100: Train Loss=12.7462, Val Loss=12.1926, Val Acc=0.1770\n",
            "Epoch 90/100: Train Loss=11.6235, Val Loss=15.0252, Val Acc=0.0780\n",
            "Epoch 91/100: Train Loss=12.3569, Val Loss=13.3840, Val Acc=0.1340\n",
            "Epoch 92/100: Train Loss=12.1639, Val Loss=12.4798, Val Acc=0.1770\n",
            "Epoch 93/100: Train Loss=13.2845, Val Loss=10.7164, Val Acc=0.0780\n",
            "Epoch 94/100: Train Loss=12.2905, Val Loss=11.6434, Val Acc=0.1340\n",
            "Epoch 95/100: Train Loss=12.9019, Val Loss=12.6198, Val Acc=0.1770\n",
            "Epoch 96/100: Train Loss=11.6370, Val Loss=14.7435, Val Acc=0.0780\n",
            "Epoch 97/100: Train Loss=12.3892, Val Loss=10.9419, Val Acc=0.1340\n",
            "Epoch 98/100: Train Loss=11.9324, Val Loss=10.8121, Val Acc=0.1770\n",
            "Epoch 99/100: Train Loss=12.8245, Val Loss=11.4584, Val Acc=0.0780\n",
            "Epoch 100/100: Train Loss=12.5130, Val Loss=13.4111, Val Acc=0.1340\n",
            "WD=5 -> Val Loss: 8.6354\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Exp2_ValLoss_WD_0.0</td><td>▁</td></tr><tr><td>Exp2_ValLoss_WD_0.0001</td><td>▁</td></tr><tr><td>Exp2_ValLoss_WD_0.001</td><td>▁</td></tr><tr><td>Exp2_ValLoss_WD_0.01</td><td>▁</td></tr><tr><td>Exp2_ValLoss_WD_1</td><td>▁</td></tr><tr><td>Exp2_ValLoss_WD_2</td><td>▁</td></tr><tr><td>Exp2_ValLoss_WD_5</td><td>▁</td></tr><tr><td>epoch</td><td>▁▂▂▂▃▅▂▂▂▃██▃▄▆▇▁▄▄▆███▂▃▂▃▃▃▃▅▇█▁▂▃▄▆▇▇</td></tr><tr><td>train_accuracy</td><td>▇██████████▇█████▄▇▇▇▇▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▇▇▇▇▇██</td></tr><tr><td>val_accuracy</td><td>█████████████▃███████▇▇▇▇▇▇▇▁▁▁▁▁▂▂▂▂▂▂▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▅▃▃▄▅▄▅▄▆▆▆▅▅▅▅█▆▆▇▆▆▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Exp2_ValLoss_WD_0.0</td><td>0.23395</td></tr><tr><td>Exp2_ValLoss_WD_0.0001</td><td>0.21992</td></tr><tr><td>Exp2_ValLoss_WD_0.001</td><td>0.21623</td></tr><tr><td>Exp2_ValLoss_WD_0.01</td><td>0.46416</td></tr><tr><td>Exp2_ValLoss_WD_1</td><td>3.66874</td></tr><tr><td>Exp2_ValLoss_WD_2</td><td>4.79799</td></tr><tr><td>Exp2_ValLoss_WD_5</td><td>8.63536</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>train_accuracy</td><td>0.121</td></tr><tr><td>train_loss</td><td>12.51297</td></tr><tr><td>val_accuracy</td><td>0.134</td></tr><tr><td>val_loss</td><td>13.4111</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">skilled-totem-2</strong> at: <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/aiguldc7' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/aiguldc7</a><br> View project at: <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250217_100759-aiguldc7/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT ANALYSIS :\n",
        "\n",
        "Our experiments varied the L2 weight decay coefficient across a wide range. The results indicate that:\n",
        "\n",
        "Low Weight Decay (0.0, 0.0001, 0.001):\n",
        "These settings yielded the best generalization performance with final validation losses around 0.217–0.224. This suggests that a small amount of or even no weight decay is sufficient for this task.\n",
        "\n",
        "Moderate to High Weight Decay (0.01):\n",
        "Increasing weight decay to 0.01 led to a notable increase in validation loss (~0.4473), indicating that the regularization is starting to impede the model’s capacity to fit the data.\n",
        "\n",
        "Excessive Weight Decay (1, 2, 5):\n",
        "When very high weight decay values were used, the model’s performance deteriorated drastically, with validation losses rising to 4.1860 for 1, 4.6607 for 2, and 8.6305 for 5. These results clearly demonstrate that over-regularization can severely hinder the learning process.\n",
        "\n",
        "Overall Assessment:\n",
        "The experiments highlight that minimal weight decay (around 0.0001–0.001) provides the best balance between preventing overfitting and preserving model capacity. The wandb run history confirms that the model is highly sensitive to the weight decay magnitude, emphasizing the need for careful hyperparameter tuning in regularization."
      ],
      "metadata": {
        "id": "_4HJVMNxTwu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C. Hidden Units Tuning:\n",
        "\n",
        "With weight decay turned off, the number of hidden units is varied (10, 30, 100, 130, 170, and 200) to identify the best model capacity."
      ],
      "metadata": {
        "id": "VnDvYbzGTzCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinitialize wandb if needed.\n",
        "if wandb.run is None:\n",
        "    wandb.init(\n",
        "        project=\"usps-digit-classification\",\n",
        "        settings=wandb.Settings(init_timeout=600)\n",
        "    )\n",
        "\n",
        "hidden_units_values = [10, 30, 100, 130, 170, 200]\n",
        "results_hu = {}\n",
        "\n",
        "for hu in hidden_units_values:\n",
        "    config_hu = {\n",
        "        'hidden_units': hu,\n",
        "        'dropout_rate': 0.5,\n",
        "        'weight_decay': 0.0,\n",
        "        'learning_rate': 0.40,\n",
        "        'momentum': 0.9,\n",
        "        'num_epochs': 100,\n",
        "        'batch_size': 100\n",
        "    }\n",
        "    print(f\"\\nRunning Experiment 3 with hidden units = {hu}\")\n",
        "    val_loss, _, _ = run_experiment(config_hu)\n",
        "    results_hu[hu] = val_loss\n",
        "    print(f\"Hidden Units={hu} -> Val Loss: {val_loss:.4f}\")\n",
        "    wandb.log({f\"Exp3_ValLoss_HU_{hu}\": val_loss})\n",
        "\n",
        "# (Optional) Locally display the plot:\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(hidden_units_values, [results_hu[hu] for hu in hidden_units_values], marker='o')\n",
        "plt.xlabel('Number of Hidden Units')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.title('Experiment 3: Val Loss vs. Hidden Units')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "wandb.finish()  # End this run when done."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SEyV89HIT1lr",
        "outputId": "103199df-d5dc-4b98-920d-813991718fde"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250217_100954-p3fbbti6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/p3fbbti6' target=\"_blank\">twilight-paper-3</a></strong> to <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/p3fbbti6' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/p3fbbti6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Experiment 3 with hidden units = 10\n",
            "Epoch 1/100: Train Loss=2.2299, Val Loss=2.0107, Val Acc=0.3170\n",
            "Epoch 2/100: Train Loss=1.8368, Val Loss=1.5219, Val Acc=0.4900\n",
            "Epoch 3/100: Train Loss=1.5548, Val Loss=1.1993, Val Acc=0.7080\n",
            "Epoch 4/100: Train Loss=1.3669, Val Loss=1.0007, Val Acc=0.7580\n",
            "Epoch 5/100: Train Loss=1.2839, Val Loss=0.9148, Val Acc=0.8020\n",
            "Epoch 6/100: Train Loss=1.1615, Val Loss=0.8100, Val Acc=0.8400\n",
            "Epoch 7/100: Train Loss=1.1544, Val Loss=0.7243, Val Acc=0.8520\n",
            "Epoch 8/100: Train Loss=1.1452, Val Loss=0.7231, Val Acc=0.8530\n",
            "Epoch 9/100: Train Loss=1.0270, Val Loss=0.6470, Val Acc=0.8750\n",
            "Epoch 10/100: Train Loss=1.0483, Val Loss=0.6253, Val Acc=0.8620\n",
            "Epoch 11/100: Train Loss=1.0483, Val Loss=0.6581, Val Acc=0.8410\n",
            "Epoch 12/100: Train Loss=1.0422, Val Loss=0.5922, Val Acc=0.8930\n",
            "Epoch 13/100: Train Loss=1.0668, Val Loss=0.6015, Val Acc=0.8770\n",
            "Epoch 14/100: Train Loss=1.0242, Val Loss=0.5944, Val Acc=0.8670\n",
            "Epoch 15/100: Train Loss=1.0344, Val Loss=0.5933, Val Acc=0.8500\n",
            "Epoch 16/100: Train Loss=1.0193, Val Loss=0.5835, Val Acc=0.8820\n",
            "Epoch 17/100: Train Loss=1.0217, Val Loss=0.5677, Val Acc=0.8840\n",
            "Epoch 18/100: Train Loss=1.0008, Val Loss=0.5836, Val Acc=0.8670\n",
            "Epoch 19/100: Train Loss=0.9865, Val Loss=0.5760, Val Acc=0.8800\n",
            "Epoch 20/100: Train Loss=0.9721, Val Loss=0.5670, Val Acc=0.8820\n",
            "Epoch 21/100: Train Loss=1.0025, Val Loss=0.5378, Val Acc=0.8880\n",
            "Epoch 22/100: Train Loss=0.9617, Val Loss=0.5549, Val Acc=0.8810\n",
            "Epoch 23/100: Train Loss=0.9736, Val Loss=0.5581, Val Acc=0.8810\n",
            "Epoch 24/100: Train Loss=0.9649, Val Loss=0.5538, Val Acc=0.8800\n",
            "Epoch 25/100: Train Loss=0.9609, Val Loss=0.5468, Val Acc=0.8680\n",
            "Epoch 26/100: Train Loss=0.9560, Val Loss=0.5497, Val Acc=0.8880\n",
            "Epoch 27/100: Train Loss=0.9661, Val Loss=0.5464, Val Acc=0.8730\n",
            "Epoch 28/100: Train Loss=0.9671, Val Loss=0.5635, Val Acc=0.8750\n",
            "Epoch 29/100: Train Loss=0.9545, Val Loss=0.5498, Val Acc=0.8760\n",
            "Epoch 30/100: Train Loss=0.9389, Val Loss=0.5701, Val Acc=0.8520\n",
            "Epoch 31/100: Train Loss=0.9407, Val Loss=0.5472, Val Acc=0.8610\n",
            "Epoch 32/100: Train Loss=0.9549, Val Loss=0.5400, Val Acc=0.8720\n",
            "Epoch 33/100: Train Loss=0.9304, Val Loss=0.5641, Val Acc=0.8580\n",
            "Epoch 34/100: Train Loss=0.9634, Val Loss=0.5538, Val Acc=0.8780\n",
            "Epoch 35/100: Train Loss=0.9954, Val Loss=0.5647, Val Acc=0.8680\n",
            "Epoch 36/100: Train Loss=0.9163, Val Loss=0.5469, Val Acc=0.8720\n",
            "Epoch 37/100: Train Loss=0.9295, Val Loss=0.5538, Val Acc=0.8730\n",
            "Epoch 38/100: Train Loss=0.9445, Val Loss=0.5478, Val Acc=0.8590\n",
            "Epoch 39/100: Train Loss=0.9344, Val Loss=0.5465, Val Acc=0.8710\n",
            "Epoch 40/100: Train Loss=0.8972, Val Loss=0.5403, Val Acc=0.8650\n",
            "Epoch 41/100: Train Loss=0.8981, Val Loss=0.5412, Val Acc=0.8690\n",
            "Epoch 42/100: Train Loss=0.9210, Val Loss=0.5345, Val Acc=0.8690\n",
            "Epoch 43/100: Train Loss=0.9127, Val Loss=0.5330, Val Acc=0.8680\n",
            "Epoch 44/100: Train Loss=0.9267, Val Loss=0.5351, Val Acc=0.8730\n",
            "Epoch 45/100: Train Loss=0.9132, Val Loss=0.5404, Val Acc=0.8760\n",
            "Epoch 46/100: Train Loss=0.9180, Val Loss=0.5442, Val Acc=0.8700\n",
            "Epoch 47/100: Train Loss=0.9051, Val Loss=0.5624, Val Acc=0.8320\n",
            "Epoch 48/100: Train Loss=0.9406, Val Loss=0.5452, Val Acc=0.8670\n",
            "Epoch 49/100: Train Loss=0.9358, Val Loss=0.5480, Val Acc=0.8640\n",
            "Epoch 50/100: Train Loss=0.9013, Val Loss=0.5638, Val Acc=0.8560\n",
            "Epoch 51/100: Train Loss=0.9230, Val Loss=0.5372, Val Acc=0.8570\n",
            "Epoch 52/100: Train Loss=0.9303, Val Loss=0.5284, Val Acc=0.8800\n",
            "Epoch 53/100: Train Loss=0.9045, Val Loss=0.5494, Val Acc=0.8680\n",
            "Epoch 54/100: Train Loss=0.8963, Val Loss=0.5144, Val Acc=0.8710\n",
            "Epoch 55/100: Train Loss=0.8665, Val Loss=0.5125, Val Acc=0.8820\n",
            "Epoch 56/100: Train Loss=0.8791, Val Loss=0.5244, Val Acc=0.8670\n",
            "Epoch 57/100: Train Loss=0.8650, Val Loss=0.5211, Val Acc=0.8730\n",
            "Epoch 58/100: Train Loss=0.8572, Val Loss=0.4965, Val Acc=0.8840\n",
            "Epoch 59/100: Train Loss=0.9031, Val Loss=0.5353, Val Acc=0.8730\n",
            "Epoch 60/100: Train Loss=0.8836, Val Loss=0.5263, Val Acc=0.8750\n",
            "Epoch 61/100: Train Loss=0.9031, Val Loss=0.5237, Val Acc=0.8750\n",
            "Epoch 62/100: Train Loss=0.9103, Val Loss=0.5366, Val Acc=0.8640\n",
            "Epoch 63/100: Train Loss=0.8514, Val Loss=0.4987, Val Acc=0.8880\n",
            "Epoch 64/100: Train Loss=0.8409, Val Loss=0.5380, Val Acc=0.8650\n",
            "Epoch 65/100: Train Loss=0.8134, Val Loss=0.5027, Val Acc=0.8770\n",
            "Epoch 66/100: Train Loss=0.8494, Val Loss=0.5102, Val Acc=0.8720\n",
            "Epoch 67/100: Train Loss=0.8329, Val Loss=0.5084, Val Acc=0.8690\n",
            "Epoch 68/100: Train Loss=0.9425, Val Loss=0.5378, Val Acc=0.8780\n",
            "Epoch 69/100: Train Loss=0.8905, Val Loss=0.5331, Val Acc=0.8750\n",
            "Epoch 70/100: Train Loss=0.8354, Val Loss=0.5406, Val Acc=0.8680\n",
            "Epoch 71/100: Train Loss=0.8717, Val Loss=0.5139, Val Acc=0.8770\n",
            "Epoch 72/100: Train Loss=0.8183, Val Loss=0.5310, Val Acc=0.8680\n",
            "Epoch 73/100: Train Loss=0.8538, Val Loss=0.5031, Val Acc=0.8800\n",
            "Epoch 74/100: Train Loss=0.8598, Val Loss=0.5406, Val Acc=0.8720\n",
            "Epoch 75/100: Train Loss=0.8789, Val Loss=0.5245, Val Acc=0.8640\n",
            "Epoch 76/100: Train Loss=0.8642, Val Loss=0.5364, Val Acc=0.8650\n",
            "Epoch 77/100: Train Loss=0.8804, Val Loss=0.5332, Val Acc=0.8750\n",
            "Epoch 78/100: Train Loss=0.8152, Val Loss=0.5275, Val Acc=0.8760\n",
            "Epoch 79/100: Train Loss=0.8988, Val Loss=0.5359, Val Acc=0.8700\n",
            "Epoch 80/100: Train Loss=0.8826, Val Loss=0.5581, Val Acc=0.8660\n",
            "Epoch 81/100: Train Loss=0.8326, Val Loss=0.5141, Val Acc=0.8710\n",
            "Epoch 82/100: Train Loss=0.8116, Val Loss=0.5052, Val Acc=0.8790\n",
            "Epoch 83/100: Train Loss=0.8332, Val Loss=0.5163, Val Acc=0.8780\n",
            "Epoch 84/100: Train Loss=0.8419, Val Loss=0.5105, Val Acc=0.8710\n",
            "Epoch 85/100: Train Loss=0.8458, Val Loss=0.5105, Val Acc=0.8840\n",
            "Epoch 86/100: Train Loss=0.8089, Val Loss=0.5253, Val Acc=0.8720\n",
            "Epoch 87/100: Train Loss=0.8233, Val Loss=0.4911, Val Acc=0.8760\n",
            "Epoch 88/100: Train Loss=0.7919, Val Loss=0.5004, Val Acc=0.8700\n",
            "Epoch 89/100: Train Loss=0.8254, Val Loss=0.4841, Val Acc=0.8880\n",
            "Epoch 90/100: Train Loss=0.8627, Val Loss=0.5229, Val Acc=0.8760\n",
            "Epoch 91/100: Train Loss=0.8649, Val Loss=0.5457, Val Acc=0.8670\n",
            "Epoch 92/100: Train Loss=0.8284, Val Loss=0.4877, Val Acc=0.8920\n",
            "Epoch 93/100: Train Loss=0.7793, Val Loss=0.5423, Val Acc=0.8750\n",
            "Epoch 94/100: Train Loss=0.8068, Val Loss=0.4974, Val Acc=0.8810\n",
            "Epoch 95/100: Train Loss=0.7750, Val Loss=0.4697, Val Acc=0.8860\n",
            "Epoch 96/100: Train Loss=0.8266, Val Loss=0.4884, Val Acc=0.8860\n",
            "Epoch 97/100: Train Loss=0.7913, Val Loss=0.5069, Val Acc=0.8860\n",
            "Epoch 98/100: Train Loss=0.8324, Val Loss=0.5102, Val Acc=0.8810\n",
            "Epoch 99/100: Train Loss=0.8223, Val Loss=0.5266, Val Acc=0.8730\n",
            "Epoch 100/100: Train Loss=0.8827, Val Loss=0.5381, Val Acc=0.8800\n",
            "Hidden Units=10 -> Val Loss: 0.4697\n",
            "\n",
            "Running Experiment 3 with hidden units = 30\n",
            "Epoch 1/100: Train Loss=2.2305, Val Loss=1.9176, Val Acc=0.3710\n",
            "Epoch 2/100: Train Loss=1.6173, Val Loss=1.1848, Val Acc=0.7000\n",
            "Epoch 3/100: Train Loss=1.0979, Val Loss=0.7279, Val Acc=0.8110\n",
            "Epoch 4/100: Train Loss=0.8103, Val Loss=0.5396, Val Acc=0.8490\n",
            "Epoch 5/100: Train Loss=0.6772, Val Loss=0.4408, Val Acc=0.8720\n",
            "Epoch 6/100: Train Loss=0.6204, Val Loss=0.3916, Val Acc=0.9060\n",
            "Epoch 7/100: Train Loss=0.5258, Val Loss=0.3453, Val Acc=0.9140\n",
            "Epoch 8/100: Train Loss=0.4855, Val Loss=0.3175, Val Acc=0.9160\n",
            "Epoch 9/100: Train Loss=0.4070, Val Loss=0.2885, Val Acc=0.9170\n",
            "Epoch 10/100: Train Loss=0.3453, Val Loss=0.2773, Val Acc=0.9200\n",
            "Epoch 11/100: Train Loss=0.3789, Val Loss=0.2779, Val Acc=0.9250\n",
            "Epoch 12/100: Train Loss=0.3530, Val Loss=0.2695, Val Acc=0.9280\n",
            "Epoch 13/100: Train Loss=0.3251, Val Loss=0.2912, Val Acc=0.9260\n",
            "Epoch 14/100: Train Loss=0.3388, Val Loss=0.2618, Val Acc=0.9260\n",
            "Epoch 15/100: Train Loss=0.3195, Val Loss=0.2603, Val Acc=0.9210\n",
            "Epoch 16/100: Train Loss=0.3051, Val Loss=0.2593, Val Acc=0.9280\n",
            "Epoch 17/100: Train Loss=0.2908, Val Loss=0.2595, Val Acc=0.9290\n",
            "Epoch 18/100: Train Loss=0.2817, Val Loss=0.2476, Val Acc=0.9300\n",
            "Epoch 19/100: Train Loss=0.2740, Val Loss=0.2475, Val Acc=0.9300\n",
            "Epoch 20/100: Train Loss=0.2758, Val Loss=0.2501, Val Acc=0.9300\n",
            "Epoch 21/100: Train Loss=0.2466, Val Loss=0.2477, Val Acc=0.9310\n",
            "Epoch 22/100: Train Loss=0.2468, Val Loss=0.2403, Val Acc=0.9320\n",
            "Epoch 23/100: Train Loss=0.2366, Val Loss=0.2432, Val Acc=0.9330\n",
            "Epoch 24/100: Train Loss=0.2144, Val Loss=0.2457, Val Acc=0.9390\n",
            "Epoch 25/100: Train Loss=0.2436, Val Loss=0.2700, Val Acc=0.9300\n",
            "Epoch 26/100: Train Loss=0.2212, Val Loss=0.2608, Val Acc=0.9310\n",
            "Epoch 27/100: Train Loss=0.2384, Val Loss=0.2388, Val Acc=0.9390\n",
            "Epoch 28/100: Train Loss=0.2528, Val Loss=0.2501, Val Acc=0.9360\n",
            "Epoch 29/100: Train Loss=0.2095, Val Loss=0.2699, Val Acc=0.9300\n",
            "Epoch 30/100: Train Loss=0.2320, Val Loss=0.2602, Val Acc=0.9340\n",
            "Epoch 31/100: Train Loss=0.2161, Val Loss=0.2471, Val Acc=0.9390\n",
            "Epoch 32/100: Train Loss=0.1998, Val Loss=0.2619, Val Acc=0.9310\n",
            "Epoch 33/100: Train Loss=0.2117, Val Loss=0.2511, Val Acc=0.9330\n",
            "Epoch 34/100: Train Loss=0.1963, Val Loss=0.2626, Val Acc=0.9310\n",
            "Epoch 35/100: Train Loss=0.1757, Val Loss=0.2463, Val Acc=0.9380\n",
            "Epoch 36/100: Train Loss=0.1938, Val Loss=0.2572, Val Acc=0.9320\n",
            "Epoch 37/100: Train Loss=0.1838, Val Loss=0.2603, Val Acc=0.9310\n",
            "Epoch 38/100: Train Loss=0.1895, Val Loss=0.2534, Val Acc=0.9360\n",
            "Epoch 39/100: Train Loss=0.2063, Val Loss=0.2510, Val Acc=0.9360\n",
            "Epoch 40/100: Train Loss=0.1853, Val Loss=0.2575, Val Acc=0.9330\n",
            "Epoch 41/100: Train Loss=0.1816, Val Loss=0.2586, Val Acc=0.9360\n",
            "Epoch 42/100: Train Loss=0.1689, Val Loss=0.2481, Val Acc=0.9360\n",
            "Epoch 43/100: Train Loss=0.1630, Val Loss=0.2753, Val Acc=0.9300\n",
            "Epoch 44/100: Train Loss=0.1504, Val Loss=0.2867, Val Acc=0.9300\n",
            "Epoch 45/100: Train Loss=0.1657, Val Loss=0.2852, Val Acc=0.9310\n",
            "Epoch 46/100: Train Loss=0.1944, Val Loss=0.2629, Val Acc=0.9380\n",
            "Epoch 47/100: Train Loss=0.1603, Val Loss=0.2873, Val Acc=0.9290\n",
            "Epoch 48/100: Train Loss=0.1635, Val Loss=0.2812, Val Acc=0.9350\n",
            "Epoch 49/100: Train Loss=0.1591, Val Loss=0.2684, Val Acc=0.9380\n",
            "Epoch 50/100: Train Loss=0.1648, Val Loss=0.2669, Val Acc=0.9390\n",
            "Epoch 51/100: Train Loss=0.1506, Val Loss=0.2838, Val Acc=0.9310\n",
            "Epoch 52/100: Train Loss=0.1327, Val Loss=0.2810, Val Acc=0.9360\n",
            "Epoch 53/100: Train Loss=0.1495, Val Loss=0.2808, Val Acc=0.9360\n",
            "Epoch 54/100: Train Loss=0.1566, Val Loss=0.2899, Val Acc=0.9340\n",
            "Epoch 55/100: Train Loss=0.1793, Val Loss=0.2944, Val Acc=0.9310\n",
            "Epoch 56/100: Train Loss=0.1405, Val Loss=0.2838, Val Acc=0.9350\n",
            "Epoch 57/100: Train Loss=0.1376, Val Loss=0.2899, Val Acc=0.9330\n",
            "Epoch 58/100: Train Loss=0.1306, Val Loss=0.2869, Val Acc=0.9330\n",
            "Epoch 59/100: Train Loss=0.1610, Val Loss=0.2846, Val Acc=0.9350\n",
            "Epoch 60/100: Train Loss=0.1409, Val Loss=0.2687, Val Acc=0.9380\n",
            "Epoch 61/100: Train Loss=0.1308, Val Loss=0.2805, Val Acc=0.9330\n",
            "Epoch 62/100: Train Loss=0.1479, Val Loss=0.3090, Val Acc=0.9320\n",
            "Epoch 63/100: Train Loss=0.1613, Val Loss=0.3159, Val Acc=0.9320\n",
            "Epoch 64/100: Train Loss=0.1489, Val Loss=0.3004, Val Acc=0.9350\n",
            "Epoch 65/100: Train Loss=0.1479, Val Loss=0.2801, Val Acc=0.9360\n",
            "Epoch 66/100: Train Loss=0.1338, Val Loss=0.2928, Val Acc=0.9350\n",
            "Epoch 67/100: Train Loss=0.1474, Val Loss=0.2848, Val Acc=0.9340\n",
            "Epoch 68/100: Train Loss=0.1527, Val Loss=0.2827, Val Acc=0.9380\n",
            "Epoch 69/100: Train Loss=0.1415, Val Loss=0.2892, Val Acc=0.9360\n",
            "Epoch 70/100: Train Loss=0.1476, Val Loss=0.2818, Val Acc=0.9390\n",
            "Epoch 71/100: Train Loss=0.1437, Val Loss=0.2875, Val Acc=0.9380\n",
            "Epoch 72/100: Train Loss=0.1404, Val Loss=0.3019, Val Acc=0.9360\n",
            "Epoch 73/100: Train Loss=0.1213, Val Loss=0.2919, Val Acc=0.9410\n",
            "Epoch 74/100: Train Loss=0.1282, Val Loss=0.3091, Val Acc=0.9350\n",
            "Epoch 75/100: Train Loss=0.1204, Val Loss=0.3188, Val Acc=0.9350\n",
            "Epoch 76/100: Train Loss=0.1471, Val Loss=0.3101, Val Acc=0.9320\n",
            "Epoch 77/100: Train Loss=0.1619, Val Loss=0.3046, Val Acc=0.9310\n",
            "Epoch 78/100: Train Loss=0.1331, Val Loss=0.2974, Val Acc=0.9360\n",
            "Epoch 79/100: Train Loss=0.1537, Val Loss=0.3098, Val Acc=0.9340\n",
            "Epoch 80/100: Train Loss=0.1401, Val Loss=0.3357, Val Acc=0.9310\n",
            "Epoch 81/100: Train Loss=0.1250, Val Loss=0.3171, Val Acc=0.9310\n",
            "Epoch 82/100: Train Loss=0.1257, Val Loss=0.3279, Val Acc=0.9340\n",
            "Epoch 83/100: Train Loss=0.1497, Val Loss=0.3286, Val Acc=0.9290\n",
            "Epoch 84/100: Train Loss=0.1348, Val Loss=0.3180, Val Acc=0.9350\n",
            "Epoch 85/100: Train Loss=0.1486, Val Loss=0.3091, Val Acc=0.9360\n",
            "Epoch 86/100: Train Loss=0.1333, Val Loss=0.3238, Val Acc=0.9290\n",
            "Epoch 87/100: Train Loss=0.1325, Val Loss=0.3373, Val Acc=0.9290\n",
            "Epoch 88/100: Train Loss=0.1160, Val Loss=0.3277, Val Acc=0.9330\n",
            "Epoch 89/100: Train Loss=0.1106, Val Loss=0.3083, Val Acc=0.9360\n",
            "Epoch 90/100: Train Loss=0.1305, Val Loss=0.3130, Val Acc=0.9340\n",
            "Epoch 91/100: Train Loss=0.1121, Val Loss=0.3284, Val Acc=0.9300\n",
            "Epoch 92/100: Train Loss=0.1445, Val Loss=0.3347, Val Acc=0.9340\n",
            "Epoch 93/100: Train Loss=0.1453, Val Loss=0.3176, Val Acc=0.9300\n",
            "Epoch 94/100: Train Loss=0.1086, Val Loss=0.3250, Val Acc=0.9330\n",
            "Epoch 95/100: Train Loss=0.1528, Val Loss=0.3298, Val Acc=0.9340\n",
            "Epoch 96/100: Train Loss=0.1402, Val Loss=0.3340, Val Acc=0.9310\n",
            "Epoch 97/100: Train Loss=0.1357, Val Loss=0.3363, Val Acc=0.9330\n",
            "Epoch 98/100: Train Loss=0.1370, Val Loss=0.3111, Val Acc=0.9340\n",
            "Epoch 99/100: Train Loss=0.1229, Val Loss=0.3150, Val Acc=0.9310\n",
            "Epoch 100/100: Train Loss=0.1179, Val Loss=0.3277, Val Acc=0.9330\n",
            "Hidden Units=30 -> Val Loss: 0.2388\n",
            "\n",
            "Running Experiment 3 with hidden units = 100\n",
            "Epoch 1/100: Train Loss=2.2612, Val Loss=1.7701, Val Acc=0.4330\n",
            "Epoch 2/100: Train Loss=1.4764, Val Loss=1.0471, Val Acc=0.6560\n",
            "Epoch 3/100: Train Loss=0.8250, Val Loss=0.5244, Val Acc=0.8460\n",
            "Epoch 4/100: Train Loss=0.5265, Val Loss=0.3821, Val Acc=0.8880\n",
            "Epoch 5/100: Train Loss=0.3713, Val Loss=0.3244, Val Acc=0.9030\n",
            "Epoch 6/100: Train Loss=0.3327, Val Loss=0.3156, Val Acc=0.9160\n",
            "Epoch 7/100: Train Loss=0.2765, Val Loss=0.2699, Val Acc=0.9280\n",
            "Epoch 8/100: Train Loss=0.2442, Val Loss=0.2517, Val Acc=0.9280\n",
            "Epoch 9/100: Train Loss=0.1872, Val Loss=0.2403, Val Acc=0.9260\n",
            "Epoch 10/100: Train Loss=0.1710, Val Loss=0.2381, Val Acc=0.9310\n",
            "Epoch 11/100: Train Loss=0.1906, Val Loss=0.2257, Val Acc=0.9340\n",
            "Epoch 12/100: Train Loss=0.1497, Val Loss=0.2321, Val Acc=0.9300\n",
            "Epoch 13/100: Train Loss=0.1585, Val Loss=0.2319, Val Acc=0.9360\n",
            "Epoch 14/100: Train Loss=0.1529, Val Loss=0.2342, Val Acc=0.9310\n",
            "Epoch 15/100: Train Loss=0.1171, Val Loss=0.2394, Val Acc=0.9310\n",
            "Epoch 16/100: Train Loss=0.1220, Val Loss=0.2321, Val Acc=0.9360\n",
            "Epoch 17/100: Train Loss=0.0983, Val Loss=0.2363, Val Acc=0.9290\n",
            "Epoch 18/100: Train Loss=0.1179, Val Loss=0.2552, Val Acc=0.9340\n",
            "Epoch 19/100: Train Loss=0.0968, Val Loss=0.2264, Val Acc=0.9330\n",
            "Epoch 20/100: Train Loss=0.0947, Val Loss=0.2381, Val Acc=0.9340\n",
            "Epoch 21/100: Train Loss=0.0908, Val Loss=0.2359, Val Acc=0.9380\n",
            "Epoch 22/100: Train Loss=0.0771, Val Loss=0.2370, Val Acc=0.9360\n",
            "Epoch 23/100: Train Loss=0.0884, Val Loss=0.2525, Val Acc=0.9310\n",
            "Epoch 24/100: Train Loss=0.0671, Val Loss=0.2416, Val Acc=0.9330\n",
            "Epoch 25/100: Train Loss=0.0766, Val Loss=0.2336, Val Acc=0.9360\n",
            "Epoch 26/100: Train Loss=0.0795, Val Loss=0.2375, Val Acc=0.9330\n",
            "Epoch 27/100: Train Loss=0.0720, Val Loss=0.2353, Val Acc=0.9330\n",
            "Epoch 28/100: Train Loss=0.0736, Val Loss=0.2399, Val Acc=0.9340\n",
            "Epoch 29/100: Train Loss=0.0707, Val Loss=0.2388, Val Acc=0.9350\n",
            "Epoch 30/100: Train Loss=0.0634, Val Loss=0.2410, Val Acc=0.9330\n",
            "Epoch 31/100: Train Loss=0.0480, Val Loss=0.2379, Val Acc=0.9350\n",
            "Epoch 32/100: Train Loss=0.0501, Val Loss=0.2430, Val Acc=0.9340\n",
            "Epoch 33/100: Train Loss=0.0534, Val Loss=0.2363, Val Acc=0.9340\n",
            "Epoch 34/100: Train Loss=0.0602, Val Loss=0.2487, Val Acc=0.9360\n",
            "Epoch 35/100: Train Loss=0.0476, Val Loss=0.2586, Val Acc=0.9340\n",
            "Epoch 36/100: Train Loss=0.0383, Val Loss=0.2555, Val Acc=0.9330\n",
            "Epoch 37/100: Train Loss=0.0583, Val Loss=0.2569, Val Acc=0.9330\n",
            "Epoch 38/100: Train Loss=0.0492, Val Loss=0.2643, Val Acc=0.9320\n",
            "Epoch 39/100: Train Loss=0.0546, Val Loss=0.2477, Val Acc=0.9380\n",
            "Epoch 40/100: Train Loss=0.0412, Val Loss=0.2435, Val Acc=0.9360\n",
            "Epoch 41/100: Train Loss=0.0458, Val Loss=0.2589, Val Acc=0.9290\n",
            "Epoch 42/100: Train Loss=0.0475, Val Loss=0.2555, Val Acc=0.9350\n",
            "Epoch 43/100: Train Loss=0.0467, Val Loss=0.2665, Val Acc=0.9360\n",
            "Epoch 44/100: Train Loss=0.0492, Val Loss=0.2534, Val Acc=0.9340\n",
            "Epoch 45/100: Train Loss=0.0400, Val Loss=0.2544, Val Acc=0.9360\n",
            "Epoch 46/100: Train Loss=0.0351, Val Loss=0.2743, Val Acc=0.9380\n",
            "Epoch 47/100: Train Loss=0.0355, Val Loss=0.2642, Val Acc=0.9320\n",
            "Epoch 48/100: Train Loss=0.0380, Val Loss=0.2609, Val Acc=0.9350\n",
            "Epoch 49/100: Train Loss=0.0414, Val Loss=0.2593, Val Acc=0.9340\n",
            "Epoch 50/100: Train Loss=0.0327, Val Loss=0.2655, Val Acc=0.9370\n",
            "Epoch 51/100: Train Loss=0.0367, Val Loss=0.2666, Val Acc=0.9370\n",
            "Epoch 52/100: Train Loss=0.0319, Val Loss=0.2710, Val Acc=0.9370\n",
            "Epoch 53/100: Train Loss=0.0319, Val Loss=0.2667, Val Acc=0.9360\n",
            "Epoch 54/100: Train Loss=0.0290, Val Loss=0.2715, Val Acc=0.9360\n",
            "Epoch 55/100: Train Loss=0.0325, Val Loss=0.2673, Val Acc=0.9350\n",
            "Epoch 56/100: Train Loss=0.0256, Val Loss=0.2712, Val Acc=0.9350\n",
            "Epoch 57/100: Train Loss=0.0305, Val Loss=0.2729, Val Acc=0.9350\n",
            "Epoch 58/100: Train Loss=0.0264, Val Loss=0.2800, Val Acc=0.9340\n",
            "Epoch 59/100: Train Loss=0.0296, Val Loss=0.2748, Val Acc=0.9370\n",
            "Epoch 60/100: Train Loss=0.0324, Val Loss=0.2749, Val Acc=0.9390\n",
            "Epoch 61/100: Train Loss=0.0359, Val Loss=0.2751, Val Acc=0.9360\n",
            "Epoch 62/100: Train Loss=0.0286, Val Loss=0.2638, Val Acc=0.9390\n",
            "Epoch 63/100: Train Loss=0.0373, Val Loss=0.2717, Val Acc=0.9370\n",
            "Epoch 64/100: Train Loss=0.0289, Val Loss=0.2694, Val Acc=0.9380\n",
            "Epoch 65/100: Train Loss=0.0273, Val Loss=0.2741, Val Acc=0.9370\n",
            "Epoch 66/100: Train Loss=0.0202, Val Loss=0.2804, Val Acc=0.9370\n",
            "Epoch 67/100: Train Loss=0.0269, Val Loss=0.2763, Val Acc=0.9370\n",
            "Epoch 68/100: Train Loss=0.0347, Val Loss=0.2701, Val Acc=0.9390\n",
            "Epoch 69/100: Train Loss=0.0317, Val Loss=0.2759, Val Acc=0.9380\n",
            "Epoch 70/100: Train Loss=0.0219, Val Loss=0.2830, Val Acc=0.9370\n",
            "Epoch 71/100: Train Loss=0.0318, Val Loss=0.2683, Val Acc=0.9380\n",
            "Epoch 72/100: Train Loss=0.0307, Val Loss=0.2679, Val Acc=0.9390\n",
            "Epoch 73/100: Train Loss=0.0320, Val Loss=0.2808, Val Acc=0.9390\n",
            "Epoch 74/100: Train Loss=0.0267, Val Loss=0.2787, Val Acc=0.9410\n",
            "Epoch 75/100: Train Loss=0.0269, Val Loss=0.2704, Val Acc=0.9400\n",
            "Epoch 76/100: Train Loss=0.0243, Val Loss=0.2782, Val Acc=0.9390\n",
            "Epoch 77/100: Train Loss=0.0309, Val Loss=0.2789, Val Acc=0.9380\n",
            "Epoch 78/100: Train Loss=0.0346, Val Loss=0.2824, Val Acc=0.9340\n",
            "Epoch 79/100: Train Loss=0.0214, Val Loss=0.2717, Val Acc=0.9330\n",
            "Epoch 80/100: Train Loss=0.0317, Val Loss=0.2666, Val Acc=0.9350\n",
            "Epoch 81/100: Train Loss=0.0243, Val Loss=0.2740, Val Acc=0.9350\n",
            "Epoch 82/100: Train Loss=0.0248, Val Loss=0.2858, Val Acc=0.9380\n",
            "Epoch 83/100: Train Loss=0.0191, Val Loss=0.2837, Val Acc=0.9360\n",
            "Epoch 84/100: Train Loss=0.0160, Val Loss=0.2726, Val Acc=0.9360\n",
            "Epoch 85/100: Train Loss=0.0148, Val Loss=0.2727, Val Acc=0.9340\n",
            "Epoch 86/100: Train Loss=0.0223, Val Loss=0.2792, Val Acc=0.9350\n",
            "Epoch 87/100: Train Loss=0.0178, Val Loss=0.2811, Val Acc=0.9370\n",
            "Epoch 88/100: Train Loss=0.0170, Val Loss=0.2844, Val Acc=0.9350\n",
            "Epoch 89/100: Train Loss=0.0289, Val Loss=0.2932, Val Acc=0.9380\n",
            "Epoch 90/100: Train Loss=0.0168, Val Loss=0.2833, Val Acc=0.9390\n",
            "Epoch 91/100: Train Loss=0.0147, Val Loss=0.2801, Val Acc=0.9370\n",
            "Epoch 92/100: Train Loss=0.0234, Val Loss=0.2897, Val Acc=0.9360\n",
            "Epoch 93/100: Train Loss=0.0173, Val Loss=0.2941, Val Acc=0.9370\n",
            "Epoch 94/100: Train Loss=0.0132, Val Loss=0.2873, Val Acc=0.9390\n",
            "Epoch 95/100: Train Loss=0.0163, Val Loss=0.2843, Val Acc=0.9370\n",
            "Epoch 96/100: Train Loss=0.0119, Val Loss=0.2855, Val Acc=0.9400\n",
            "Epoch 97/100: Train Loss=0.0116, Val Loss=0.2924, Val Acc=0.9380\n",
            "Epoch 98/100: Train Loss=0.0134, Val Loss=0.2943, Val Acc=0.9380\n",
            "Epoch 99/100: Train Loss=0.0140, Val Loss=0.2919, Val Acc=0.9390\n",
            "Epoch 100/100: Train Loss=0.0256, Val Loss=0.2995, Val Acc=0.9340\n",
            "Hidden Units=100 -> Val Loss: 0.2257\n",
            "\n",
            "Running Experiment 3 with hidden units = 130\n",
            "Epoch 1/100: Train Loss=2.4680, Val Loss=1.8207, Val Acc=0.4340\n",
            "Epoch 2/100: Train Loss=1.3617, Val Loss=0.8577, Val Acc=0.7430\n",
            "Epoch 3/100: Train Loss=0.7076, Val Loss=0.4592, Val Acc=0.8600\n",
            "Epoch 4/100: Train Loss=0.4550, Val Loss=0.3726, Val Acc=0.8870\n",
            "Epoch 5/100: Train Loss=0.3451, Val Loss=0.3045, Val Acc=0.9090\n",
            "Epoch 6/100: Train Loss=0.2836, Val Loss=0.2978, Val Acc=0.9170\n",
            "Epoch 7/100: Train Loss=0.2343, Val Loss=0.2491, Val Acc=0.9240\n",
            "Epoch 8/100: Train Loss=0.2054, Val Loss=0.2450, Val Acc=0.9270\n",
            "Epoch 9/100: Train Loss=0.2054, Val Loss=0.2444, Val Acc=0.9290\n",
            "Epoch 10/100: Train Loss=0.1800, Val Loss=0.2333, Val Acc=0.9320\n",
            "Epoch 11/100: Train Loss=0.1391, Val Loss=0.2378, Val Acc=0.9340\n",
            "Epoch 12/100: Train Loss=0.1736, Val Loss=0.2370, Val Acc=0.9320\n",
            "Epoch 13/100: Train Loss=0.1464, Val Loss=0.2272, Val Acc=0.9370\n",
            "Epoch 14/100: Train Loss=0.1216, Val Loss=0.2343, Val Acc=0.9340\n",
            "Epoch 15/100: Train Loss=0.1299, Val Loss=0.2427, Val Acc=0.9340\n",
            "Epoch 16/100: Train Loss=0.0967, Val Loss=0.2289, Val Acc=0.9340\n",
            "Epoch 17/100: Train Loss=0.1194, Val Loss=0.2433, Val Acc=0.9360\n",
            "Epoch 18/100: Train Loss=0.0949, Val Loss=0.2284, Val Acc=0.9330\n",
            "Epoch 19/100: Train Loss=0.0912, Val Loss=0.2366, Val Acc=0.9310\n",
            "Epoch 20/100: Train Loss=0.0810, Val Loss=0.2352, Val Acc=0.9330\n",
            "Epoch 21/100: Train Loss=0.0833, Val Loss=0.2357, Val Acc=0.9340\n",
            "Epoch 22/100: Train Loss=0.0750, Val Loss=0.2440, Val Acc=0.9340\n",
            "Epoch 23/100: Train Loss=0.0623, Val Loss=0.2365, Val Acc=0.9370\n",
            "Epoch 24/100: Train Loss=0.0689, Val Loss=0.2473, Val Acc=0.9370\n",
            "Epoch 25/100: Train Loss=0.0666, Val Loss=0.2403, Val Acc=0.9350\n",
            "Epoch 26/100: Train Loss=0.0579, Val Loss=0.2375, Val Acc=0.9340\n",
            "Epoch 27/100: Train Loss=0.0647, Val Loss=0.2362, Val Acc=0.9380\n",
            "Epoch 28/100: Train Loss=0.0541, Val Loss=0.2469, Val Acc=0.9350\n",
            "Epoch 29/100: Train Loss=0.0569, Val Loss=0.2602, Val Acc=0.9350\n",
            "Epoch 30/100: Train Loss=0.0689, Val Loss=0.2392, Val Acc=0.9360\n",
            "Epoch 31/100: Train Loss=0.0436, Val Loss=0.2477, Val Acc=0.9400\n",
            "Epoch 32/100: Train Loss=0.0565, Val Loss=0.2483, Val Acc=0.9370\n",
            "Epoch 33/100: Train Loss=0.0517, Val Loss=0.2492, Val Acc=0.9370\n",
            "Epoch 34/100: Train Loss=0.0394, Val Loss=0.2473, Val Acc=0.9350\n",
            "Epoch 35/100: Train Loss=0.0501, Val Loss=0.2500, Val Acc=0.9370\n",
            "Epoch 36/100: Train Loss=0.0433, Val Loss=0.2531, Val Acc=0.9390\n",
            "Epoch 37/100: Train Loss=0.0536, Val Loss=0.2515, Val Acc=0.9350\n",
            "Epoch 38/100: Train Loss=0.0412, Val Loss=0.2490, Val Acc=0.9370\n",
            "Epoch 39/100: Train Loss=0.0383, Val Loss=0.2620, Val Acc=0.9380\n",
            "Epoch 40/100: Train Loss=0.0334, Val Loss=0.2591, Val Acc=0.9350\n",
            "Epoch 41/100: Train Loss=0.0384, Val Loss=0.2567, Val Acc=0.9370\n",
            "Epoch 42/100: Train Loss=0.0379, Val Loss=0.2638, Val Acc=0.9340\n",
            "Epoch 43/100: Train Loss=0.0403, Val Loss=0.2655, Val Acc=0.9370\n",
            "Epoch 44/100: Train Loss=0.0402, Val Loss=0.2589, Val Acc=0.9340\n",
            "Epoch 45/100: Train Loss=0.0360, Val Loss=0.2553, Val Acc=0.9370\n",
            "Epoch 46/100: Train Loss=0.0310, Val Loss=0.2586, Val Acc=0.9350\n",
            "Epoch 47/100: Train Loss=0.0333, Val Loss=0.2501, Val Acc=0.9390\n",
            "Epoch 48/100: Train Loss=0.0305, Val Loss=0.2679, Val Acc=0.9350\n",
            "Epoch 49/100: Train Loss=0.0322, Val Loss=0.2571, Val Acc=0.9370\n",
            "Epoch 50/100: Train Loss=0.0210, Val Loss=0.2599, Val Acc=0.9360\n",
            "Epoch 51/100: Train Loss=0.0218, Val Loss=0.2685, Val Acc=0.9340\n",
            "Epoch 52/100: Train Loss=0.0282, Val Loss=0.2708, Val Acc=0.9340\n",
            "Epoch 53/100: Train Loss=0.0333, Val Loss=0.2662, Val Acc=0.9410\n",
            "Epoch 54/100: Train Loss=0.0372, Val Loss=0.2638, Val Acc=0.9380\n",
            "Epoch 55/100: Train Loss=0.0285, Val Loss=0.2633, Val Acc=0.9400\n",
            "Epoch 56/100: Train Loss=0.0215, Val Loss=0.2643, Val Acc=0.9390\n",
            "Epoch 57/100: Train Loss=0.0280, Val Loss=0.2639, Val Acc=0.9370\n",
            "Epoch 58/100: Train Loss=0.0294, Val Loss=0.2626, Val Acc=0.9350\n",
            "Epoch 59/100: Train Loss=0.0210, Val Loss=0.2544, Val Acc=0.9390\n",
            "Epoch 60/100: Train Loss=0.0298, Val Loss=0.2740, Val Acc=0.9380\n",
            "Epoch 61/100: Train Loss=0.0287, Val Loss=0.2609, Val Acc=0.9390\n",
            "Epoch 62/100: Train Loss=0.0220, Val Loss=0.2562, Val Acc=0.9400\n",
            "Epoch 63/100: Train Loss=0.0210, Val Loss=0.2561, Val Acc=0.9420\n",
            "Epoch 64/100: Train Loss=0.0258, Val Loss=0.2588, Val Acc=0.9370\n",
            "Epoch 65/100: Train Loss=0.0224, Val Loss=0.2610, Val Acc=0.9360\n",
            "Epoch 66/100: Train Loss=0.0202, Val Loss=0.2654, Val Acc=0.9380\n",
            "Epoch 67/100: Train Loss=0.0186, Val Loss=0.2705, Val Acc=0.9400\n",
            "Epoch 68/100: Train Loss=0.0242, Val Loss=0.2728, Val Acc=0.9400\n",
            "Epoch 69/100: Train Loss=0.0201, Val Loss=0.2677, Val Acc=0.9360\n",
            "Epoch 70/100: Train Loss=0.0208, Val Loss=0.2720, Val Acc=0.9380\n",
            "Epoch 71/100: Train Loss=0.0241, Val Loss=0.2568, Val Acc=0.9390\n",
            "Epoch 72/100: Train Loss=0.0191, Val Loss=0.2689, Val Acc=0.9390\n",
            "Epoch 73/100: Train Loss=0.0176, Val Loss=0.2756, Val Acc=0.9370\n",
            "Epoch 74/100: Train Loss=0.0205, Val Loss=0.2739, Val Acc=0.9370\n",
            "Epoch 75/100: Train Loss=0.0210, Val Loss=0.2764, Val Acc=0.9390\n",
            "Epoch 76/100: Train Loss=0.0146, Val Loss=0.2873, Val Acc=0.9360\n",
            "Epoch 77/100: Train Loss=0.0153, Val Loss=0.2813, Val Acc=0.9370\n",
            "Epoch 78/100: Train Loss=0.0162, Val Loss=0.2731, Val Acc=0.9380\n",
            "Epoch 79/100: Train Loss=0.0160, Val Loss=0.2750, Val Acc=0.9380\n",
            "Epoch 80/100: Train Loss=0.0103, Val Loss=0.2794, Val Acc=0.9380\n",
            "Epoch 81/100: Train Loss=0.0166, Val Loss=0.2810, Val Acc=0.9380\n",
            "Epoch 82/100: Train Loss=0.0201, Val Loss=0.2832, Val Acc=0.9370\n",
            "Epoch 83/100: Train Loss=0.0162, Val Loss=0.2835, Val Acc=0.9380\n",
            "Epoch 84/100: Train Loss=0.0181, Val Loss=0.2821, Val Acc=0.9370\n",
            "Epoch 85/100: Train Loss=0.0165, Val Loss=0.2818, Val Acc=0.9380\n",
            "Epoch 86/100: Train Loss=0.0209, Val Loss=0.2809, Val Acc=0.9390\n",
            "Epoch 87/100: Train Loss=0.0242, Val Loss=0.2784, Val Acc=0.9430\n",
            "Epoch 88/100: Train Loss=0.0221, Val Loss=0.2700, Val Acc=0.9400\n",
            "Epoch 89/100: Train Loss=0.0193, Val Loss=0.2738, Val Acc=0.9340\n",
            "Epoch 90/100: Train Loss=0.0201, Val Loss=0.2771, Val Acc=0.9350\n",
            "Epoch 91/100: Train Loss=0.0259, Val Loss=0.2913, Val Acc=0.9370\n",
            "Epoch 92/100: Train Loss=0.0190, Val Loss=0.2965, Val Acc=0.9370\n",
            "Epoch 93/100: Train Loss=0.0136, Val Loss=0.3014, Val Acc=0.9370\n",
            "Epoch 94/100: Train Loss=0.0142, Val Loss=0.2987, Val Acc=0.9370\n",
            "Epoch 95/100: Train Loss=0.0159, Val Loss=0.2914, Val Acc=0.9380\n",
            "Epoch 96/100: Train Loss=0.0129, Val Loss=0.2895, Val Acc=0.9430\n",
            "Epoch 97/100: Train Loss=0.0099, Val Loss=0.2920, Val Acc=0.9420\n",
            "Epoch 98/100: Train Loss=0.0100, Val Loss=0.2933, Val Acc=0.9450\n",
            "Epoch 99/100: Train Loss=0.0080, Val Loss=0.2917, Val Acc=0.9430\n",
            "Epoch 100/100: Train Loss=0.0111, Val Loss=0.2875, Val Acc=0.9390\n",
            "Hidden Units=130 -> Val Loss: 0.2272\n",
            "\n",
            "Running Experiment 3 with hidden units = 170\n",
            "Epoch 1/100: Train Loss=2.4112, Val Loss=1.7054, Val Acc=0.4860\n",
            "Epoch 2/100: Train Loss=1.3370, Val Loss=0.8938, Val Acc=0.7210\n",
            "Epoch 3/100: Train Loss=0.7092, Val Loss=0.5225, Val Acc=0.8260\n",
            "Epoch 4/100: Train Loss=0.4334, Val Loss=0.3370, Val Acc=0.9000\n",
            "Epoch 5/100: Train Loss=0.3295, Val Loss=0.3166, Val Acc=0.9050\n",
            "Epoch 6/100: Train Loss=0.2589, Val Loss=0.2749, Val Acc=0.9230\n",
            "Epoch 7/100: Train Loss=0.2089, Val Loss=0.2484, Val Acc=0.9250\n",
            "Epoch 8/100: Train Loss=0.2155, Val Loss=0.2701, Val Acc=0.9280\n",
            "Epoch 9/100: Train Loss=0.1729, Val Loss=0.2530, Val Acc=0.9290\n",
            "Epoch 10/100: Train Loss=0.1668, Val Loss=0.2381, Val Acc=0.9270\n",
            "Epoch 11/100: Train Loss=0.1571, Val Loss=0.2590, Val Acc=0.9300\n",
            "Epoch 12/100: Train Loss=0.1397, Val Loss=0.2366, Val Acc=0.9310\n",
            "Epoch 13/100: Train Loss=0.1234, Val Loss=0.2364, Val Acc=0.9340\n",
            "Epoch 14/100: Train Loss=0.0939, Val Loss=0.2392, Val Acc=0.9380\n",
            "Epoch 15/100: Train Loss=0.0961, Val Loss=0.2448, Val Acc=0.9340\n",
            "Epoch 16/100: Train Loss=0.1035, Val Loss=0.2329, Val Acc=0.9350\n",
            "Epoch 17/100: Train Loss=0.0927, Val Loss=0.2353, Val Acc=0.9350\n",
            "Epoch 18/100: Train Loss=0.0755, Val Loss=0.2349, Val Acc=0.9340\n",
            "Epoch 19/100: Train Loss=0.0850, Val Loss=0.2390, Val Acc=0.9340\n",
            "Epoch 20/100: Train Loss=0.0723, Val Loss=0.2318, Val Acc=0.9340\n",
            "Epoch 21/100: Train Loss=0.0839, Val Loss=0.2512, Val Acc=0.9300\n",
            "Epoch 22/100: Train Loss=0.0673, Val Loss=0.2389, Val Acc=0.9350\n",
            "Epoch 23/100: Train Loss=0.0544, Val Loss=0.2418, Val Acc=0.9350\n",
            "Epoch 24/100: Train Loss=0.0514, Val Loss=0.2331, Val Acc=0.9370\n",
            "Epoch 25/100: Train Loss=0.0692, Val Loss=0.2317, Val Acc=0.9400\n",
            "Epoch 26/100: Train Loss=0.0499, Val Loss=0.2272, Val Acc=0.9380\n",
            "Epoch 27/100: Train Loss=0.0485, Val Loss=0.2385, Val Acc=0.9370\n",
            "Epoch 28/100: Train Loss=0.0423, Val Loss=0.2386, Val Acc=0.9350\n",
            "Epoch 29/100: Train Loss=0.0621, Val Loss=0.2549, Val Acc=0.9360\n",
            "Epoch 30/100: Train Loss=0.0384, Val Loss=0.2584, Val Acc=0.9340\n",
            "Epoch 31/100: Train Loss=0.0514, Val Loss=0.2563, Val Acc=0.9340\n",
            "Epoch 32/100: Train Loss=0.0577, Val Loss=0.2473, Val Acc=0.9400\n",
            "Epoch 33/100: Train Loss=0.0427, Val Loss=0.2373, Val Acc=0.9400\n",
            "Epoch 34/100: Train Loss=0.0301, Val Loss=0.2416, Val Acc=0.9390\n",
            "Epoch 35/100: Train Loss=0.0342, Val Loss=0.2460, Val Acc=0.9350\n",
            "Epoch 36/100: Train Loss=0.0373, Val Loss=0.2436, Val Acc=0.9410\n",
            "Epoch 37/100: Train Loss=0.0333, Val Loss=0.2460, Val Acc=0.9410\n",
            "Epoch 38/100: Train Loss=0.0339, Val Loss=0.2516, Val Acc=0.9400\n",
            "Epoch 39/100: Train Loss=0.0347, Val Loss=0.2442, Val Acc=0.9370\n",
            "Epoch 40/100: Train Loss=0.0349, Val Loss=0.2481, Val Acc=0.9420\n",
            "Epoch 41/100: Train Loss=0.0283, Val Loss=0.2560, Val Acc=0.9350\n",
            "Epoch 42/100: Train Loss=0.0368, Val Loss=0.2527, Val Acc=0.9370\n",
            "Epoch 43/100: Train Loss=0.0313, Val Loss=0.2497, Val Acc=0.9370\n",
            "Epoch 44/100: Train Loss=0.0303, Val Loss=0.2546, Val Acc=0.9330\n",
            "Epoch 45/100: Train Loss=0.0348, Val Loss=0.2497, Val Acc=0.9410\n",
            "Epoch 46/100: Train Loss=0.0260, Val Loss=0.2573, Val Acc=0.9430\n",
            "Epoch 47/100: Train Loss=0.0245, Val Loss=0.2654, Val Acc=0.9420\n",
            "Epoch 48/100: Train Loss=0.0257, Val Loss=0.2652, Val Acc=0.9410\n",
            "Epoch 49/100: Train Loss=0.0299, Val Loss=0.2626, Val Acc=0.9410\n",
            "Epoch 50/100: Train Loss=0.0242, Val Loss=0.2618, Val Acc=0.9350\n",
            "Epoch 51/100: Train Loss=0.0319, Val Loss=0.2666, Val Acc=0.9360\n",
            "Epoch 52/100: Train Loss=0.0302, Val Loss=0.2634, Val Acc=0.9380\n",
            "Epoch 53/100: Train Loss=0.0266, Val Loss=0.2507, Val Acc=0.9360\n",
            "Epoch 54/100: Train Loss=0.0243, Val Loss=0.2576, Val Acc=0.9400\n",
            "Epoch 55/100: Train Loss=0.0295, Val Loss=0.2535, Val Acc=0.9430\n",
            "Epoch 56/100: Train Loss=0.0221, Val Loss=0.2513, Val Acc=0.9400\n",
            "Epoch 57/100: Train Loss=0.0312, Val Loss=0.2489, Val Acc=0.9410\n",
            "Epoch 58/100: Train Loss=0.0272, Val Loss=0.2529, Val Acc=0.9390\n",
            "Epoch 59/100: Train Loss=0.0266, Val Loss=0.2662, Val Acc=0.9410\n",
            "Epoch 60/100: Train Loss=0.0182, Val Loss=0.2655, Val Acc=0.9400\n",
            "Epoch 61/100: Train Loss=0.0212, Val Loss=0.2684, Val Acc=0.9430\n",
            "Epoch 62/100: Train Loss=0.0152, Val Loss=0.2658, Val Acc=0.9380\n",
            "Epoch 63/100: Train Loss=0.0209, Val Loss=0.2577, Val Acc=0.9380\n",
            "Epoch 64/100: Train Loss=0.0228, Val Loss=0.2614, Val Acc=0.9410\n",
            "Epoch 65/100: Train Loss=0.0126, Val Loss=0.2747, Val Acc=0.9430\n",
            "Epoch 66/100: Train Loss=0.0163, Val Loss=0.2695, Val Acc=0.9400\n",
            "Epoch 67/100: Train Loss=0.0217, Val Loss=0.2656, Val Acc=0.9380\n",
            "Epoch 68/100: Train Loss=0.0177, Val Loss=0.2627, Val Acc=0.9360\n",
            "Epoch 69/100: Train Loss=0.0160, Val Loss=0.2696, Val Acc=0.9360\n",
            "Epoch 70/100: Train Loss=0.0198, Val Loss=0.2706, Val Acc=0.9390\n",
            "Epoch 71/100: Train Loss=0.0243, Val Loss=0.2697, Val Acc=0.9400\n",
            "Epoch 72/100: Train Loss=0.0185, Val Loss=0.2752, Val Acc=0.9350\n",
            "Epoch 73/100: Train Loss=0.0196, Val Loss=0.2744, Val Acc=0.9400\n",
            "Epoch 74/100: Train Loss=0.0183, Val Loss=0.2705, Val Acc=0.9380\n",
            "Epoch 75/100: Train Loss=0.0158, Val Loss=0.2659, Val Acc=0.9400\n",
            "Epoch 76/100: Train Loss=0.0165, Val Loss=0.2677, Val Acc=0.9400\n",
            "Epoch 77/100: Train Loss=0.0150, Val Loss=0.2781, Val Acc=0.9410\n",
            "Epoch 78/100: Train Loss=0.0086, Val Loss=0.2855, Val Acc=0.9370\n",
            "Epoch 79/100: Train Loss=0.0180, Val Loss=0.2782, Val Acc=0.9400\n",
            "Epoch 80/100: Train Loss=0.0132, Val Loss=0.2771, Val Acc=0.9400\n",
            "Epoch 81/100: Train Loss=0.0124, Val Loss=0.2800, Val Acc=0.9400\n",
            "Epoch 82/100: Train Loss=0.0176, Val Loss=0.2906, Val Acc=0.9370\n",
            "Epoch 83/100: Train Loss=0.0115, Val Loss=0.2766, Val Acc=0.9380\n",
            "Epoch 84/100: Train Loss=0.0119, Val Loss=0.2688, Val Acc=0.9410\n",
            "Epoch 85/100: Train Loss=0.0085, Val Loss=0.2740, Val Acc=0.9410\n",
            "Epoch 86/100: Train Loss=0.0107, Val Loss=0.2873, Val Acc=0.9370\n",
            "Epoch 87/100: Train Loss=0.0223, Val Loss=0.2838, Val Acc=0.9380\n",
            "Epoch 88/100: Train Loss=0.0093, Val Loss=0.2831, Val Acc=0.9370\n",
            "Epoch 89/100: Train Loss=0.0145, Val Loss=0.2875, Val Acc=0.9390\n",
            "Epoch 90/100: Train Loss=0.0094, Val Loss=0.2893, Val Acc=0.9370\n",
            "Epoch 91/100: Train Loss=0.0087, Val Loss=0.2885, Val Acc=0.9420\n",
            "Epoch 92/100: Train Loss=0.0147, Val Loss=0.2865, Val Acc=0.9420\n",
            "Epoch 93/100: Train Loss=0.0064, Val Loss=0.2880, Val Acc=0.9410\n",
            "Epoch 94/100: Train Loss=0.0103, Val Loss=0.2848, Val Acc=0.9420\n",
            "Epoch 95/100: Train Loss=0.0087, Val Loss=0.2834, Val Acc=0.9420\n",
            "Epoch 96/100: Train Loss=0.0125, Val Loss=0.2853, Val Acc=0.9380\n",
            "Epoch 97/100: Train Loss=0.0091, Val Loss=0.2909, Val Acc=0.9410\n",
            "Epoch 98/100: Train Loss=0.0103, Val Loss=0.2851, Val Acc=0.9390\n",
            "Epoch 99/100: Train Loss=0.0133, Val Loss=0.2737, Val Acc=0.9450\n",
            "Epoch 100/100: Train Loss=0.0107, Val Loss=0.2690, Val Acc=0.9440\n",
            "Hidden Units=170 -> Val Loss: 0.2272\n",
            "\n",
            "Running Experiment 3 with hidden units = 200\n",
            "Epoch 1/100: Train Loss=2.6302, Val Loss=2.5500, Val Acc=0.4260\n",
            "Epoch 2/100: Train Loss=1.6321, Val Loss=1.0298, Val Acc=0.7000\n",
            "Epoch 3/100: Train Loss=0.8270, Val Loss=0.5692, Val Acc=0.7980\n",
            "Epoch 4/100: Train Loss=0.4699, Val Loss=0.3755, Val Acc=0.8820\n",
            "Epoch 5/100: Train Loss=0.3320, Val Loss=0.3361, Val Acc=0.9120\n",
            "Epoch 6/100: Train Loss=0.2754, Val Loss=0.2817, Val Acc=0.9140\n",
            "Epoch 7/100: Train Loss=0.2435, Val Loss=0.2600, Val Acc=0.9270\n",
            "Epoch 8/100: Train Loss=0.2019, Val Loss=0.2584, Val Acc=0.9290\n",
            "Epoch 9/100: Train Loss=0.1707, Val Loss=0.2558, Val Acc=0.9220\n",
            "Epoch 10/100: Train Loss=0.1571, Val Loss=0.2396, Val Acc=0.9330\n",
            "Epoch 11/100: Train Loss=0.1491, Val Loss=0.2638, Val Acc=0.9270\n",
            "Epoch 12/100: Train Loss=0.1415, Val Loss=0.2433, Val Acc=0.9320\n",
            "Epoch 13/100: Train Loss=0.1182, Val Loss=0.2524, Val Acc=0.9330\n",
            "Epoch 14/100: Train Loss=0.1222, Val Loss=0.2328, Val Acc=0.9360\n",
            "Epoch 15/100: Train Loss=0.0929, Val Loss=0.2269, Val Acc=0.9360\n",
            "Epoch 16/100: Train Loss=0.0829, Val Loss=0.2383, Val Acc=0.9340\n",
            "Epoch 17/100: Train Loss=0.0952, Val Loss=0.2298, Val Acc=0.9310\n",
            "Epoch 18/100: Train Loss=0.0876, Val Loss=0.2352, Val Acc=0.9360\n",
            "Epoch 19/100: Train Loss=0.0791, Val Loss=0.2429, Val Acc=0.9380\n",
            "Epoch 20/100: Train Loss=0.0715, Val Loss=0.2327, Val Acc=0.9370\n",
            "Epoch 21/100: Train Loss=0.0803, Val Loss=0.2483, Val Acc=0.9390\n",
            "Epoch 22/100: Train Loss=0.0623, Val Loss=0.2404, Val Acc=0.9360\n",
            "Epoch 23/100: Train Loss=0.0624, Val Loss=0.2328, Val Acc=0.9360\n",
            "Epoch 24/100: Train Loss=0.0574, Val Loss=0.2408, Val Acc=0.9340\n",
            "Epoch 25/100: Train Loss=0.0594, Val Loss=0.2441, Val Acc=0.9370\n",
            "Epoch 26/100: Train Loss=0.0692, Val Loss=0.2320, Val Acc=0.9370\n",
            "Epoch 27/100: Train Loss=0.0471, Val Loss=0.2300, Val Acc=0.9350\n",
            "Epoch 28/100: Train Loss=0.0443, Val Loss=0.2393, Val Acc=0.9420\n",
            "Epoch 29/100: Train Loss=0.0560, Val Loss=0.2465, Val Acc=0.9390\n",
            "Epoch 30/100: Train Loss=0.0523, Val Loss=0.2400, Val Acc=0.9360\n",
            "Epoch 31/100: Train Loss=0.0466, Val Loss=0.2355, Val Acc=0.9360\n",
            "Epoch 32/100: Train Loss=0.0412, Val Loss=0.2339, Val Acc=0.9380\n",
            "Epoch 33/100: Train Loss=0.0499, Val Loss=0.2413, Val Acc=0.9410\n",
            "Epoch 34/100: Train Loss=0.0373, Val Loss=0.2464, Val Acc=0.9380\n",
            "Epoch 35/100: Train Loss=0.0388, Val Loss=0.2453, Val Acc=0.9390\n",
            "Epoch 36/100: Train Loss=0.0248, Val Loss=0.2487, Val Acc=0.9380\n",
            "Epoch 37/100: Train Loss=0.0444, Val Loss=0.2659, Val Acc=0.9360\n",
            "Epoch 38/100: Train Loss=0.0327, Val Loss=0.2566, Val Acc=0.9400\n",
            "Epoch 39/100: Train Loss=0.0314, Val Loss=0.2547, Val Acc=0.9410\n",
            "Epoch 40/100: Train Loss=0.0443, Val Loss=0.2691, Val Acc=0.9340\n",
            "Epoch 41/100: Train Loss=0.0248, Val Loss=0.2655, Val Acc=0.9390\n",
            "Epoch 42/100: Train Loss=0.0329, Val Loss=0.2460, Val Acc=0.9390\n",
            "Epoch 43/100: Train Loss=0.0267, Val Loss=0.2502, Val Acc=0.9380\n",
            "Epoch 44/100: Train Loss=0.0324, Val Loss=0.2477, Val Acc=0.9420\n",
            "Epoch 45/100: Train Loss=0.0298, Val Loss=0.2508, Val Acc=0.9410\n",
            "Epoch 46/100: Train Loss=0.0227, Val Loss=0.2509, Val Acc=0.9410\n",
            "Epoch 47/100: Train Loss=0.0304, Val Loss=0.2520, Val Acc=0.9390\n",
            "Epoch 48/100: Train Loss=0.0202, Val Loss=0.2563, Val Acc=0.9370\n",
            "Epoch 49/100: Train Loss=0.0234, Val Loss=0.2560, Val Acc=0.9400\n",
            "Epoch 50/100: Train Loss=0.0210, Val Loss=0.2650, Val Acc=0.9380\n",
            "Epoch 51/100: Train Loss=0.0178, Val Loss=0.2682, Val Acc=0.9380\n",
            "Epoch 52/100: Train Loss=0.0371, Val Loss=0.2629, Val Acc=0.9360\n",
            "Epoch 53/100: Train Loss=0.0248, Val Loss=0.2879, Val Acc=0.9350\n",
            "Epoch 54/100: Train Loss=0.0272, Val Loss=0.2867, Val Acc=0.9350\n",
            "Epoch 55/100: Train Loss=0.0295, Val Loss=0.2667, Val Acc=0.9350\n",
            "Epoch 56/100: Train Loss=0.0154, Val Loss=0.2617, Val Acc=0.9400\n",
            "Epoch 57/100: Train Loss=0.0220, Val Loss=0.2639, Val Acc=0.9370\n",
            "Epoch 58/100: Train Loss=0.0286, Val Loss=0.2780, Val Acc=0.9360\n",
            "Epoch 59/100: Train Loss=0.0160, Val Loss=0.2798, Val Acc=0.9370\n",
            "Epoch 60/100: Train Loss=0.0198, Val Loss=0.2878, Val Acc=0.9390\n",
            "Epoch 61/100: Train Loss=0.0227, Val Loss=0.2818, Val Acc=0.9380\n",
            "Epoch 62/100: Train Loss=0.0163, Val Loss=0.2725, Val Acc=0.9350\n",
            "Epoch 63/100: Train Loss=0.0276, Val Loss=0.2778, Val Acc=0.9380\n",
            "Epoch 64/100: Train Loss=0.0219, Val Loss=0.2713, Val Acc=0.9360\n",
            "Epoch 65/100: Train Loss=0.0224, Val Loss=0.2674, Val Acc=0.9420\n",
            "Epoch 66/100: Train Loss=0.0167, Val Loss=0.2790, Val Acc=0.9390\n",
            "Epoch 67/100: Train Loss=0.0162, Val Loss=0.2797, Val Acc=0.9400\n",
            "Epoch 68/100: Train Loss=0.0146, Val Loss=0.2836, Val Acc=0.9400\n",
            "Epoch 69/100: Train Loss=0.0183, Val Loss=0.2822, Val Acc=0.9380\n",
            "Epoch 70/100: Train Loss=0.0149, Val Loss=0.2837, Val Acc=0.9390\n",
            "Epoch 71/100: Train Loss=0.0206, Val Loss=0.2820, Val Acc=0.9400\n",
            "Epoch 72/100: Train Loss=0.0140, Val Loss=0.2873, Val Acc=0.9420\n",
            "Epoch 73/100: Train Loss=0.0188, Val Loss=0.2937, Val Acc=0.9400\n",
            "Epoch 74/100: Train Loss=0.0103, Val Loss=0.2997, Val Acc=0.9370\n",
            "Epoch 75/100: Train Loss=0.0155, Val Loss=0.2899, Val Acc=0.9410\n",
            "Epoch 76/100: Train Loss=0.0114, Val Loss=0.2819, Val Acc=0.9400\n",
            "Epoch 77/100: Train Loss=0.0110, Val Loss=0.2851, Val Acc=0.9410\n",
            "Epoch 78/100: Train Loss=0.0117, Val Loss=0.2942, Val Acc=0.9370\n",
            "Epoch 79/100: Train Loss=0.0104, Val Loss=0.2921, Val Acc=0.9390\n",
            "Epoch 80/100: Train Loss=0.0225, Val Loss=0.2953, Val Acc=0.9380\n",
            "Epoch 81/100: Train Loss=0.0146, Val Loss=0.2909, Val Acc=0.9390\n",
            "Epoch 82/100: Train Loss=0.0175, Val Loss=0.2832, Val Acc=0.9410\n",
            "Epoch 83/100: Train Loss=0.0188, Val Loss=0.2810, Val Acc=0.9380\n",
            "Epoch 84/100: Train Loss=0.0160, Val Loss=0.2843, Val Acc=0.9370\n",
            "Epoch 85/100: Train Loss=0.0139, Val Loss=0.2823, Val Acc=0.9410\n",
            "Epoch 86/100: Train Loss=0.0121, Val Loss=0.2811, Val Acc=0.9430\n",
            "Epoch 87/100: Train Loss=0.0125, Val Loss=0.2878, Val Acc=0.9370\n",
            "Epoch 88/100: Train Loss=0.0085, Val Loss=0.2890, Val Acc=0.9380\n",
            "Epoch 89/100: Train Loss=0.0132, Val Loss=0.2868, Val Acc=0.9400\n",
            "Epoch 90/100: Train Loss=0.0101, Val Loss=0.2900, Val Acc=0.9410\n",
            "Epoch 91/100: Train Loss=0.0104, Val Loss=0.3023, Val Acc=0.9380\n",
            "Epoch 92/100: Train Loss=0.0109, Val Loss=0.3013, Val Acc=0.9380\n",
            "Epoch 93/100: Train Loss=0.0109, Val Loss=0.3042, Val Acc=0.9400\n",
            "Epoch 94/100: Train Loss=0.0103, Val Loss=0.2956, Val Acc=0.9420\n",
            "Epoch 95/100: Train Loss=0.0177, Val Loss=0.3017, Val Acc=0.9410\n",
            "Epoch 96/100: Train Loss=0.0095, Val Loss=0.3085, Val Acc=0.9380\n",
            "Epoch 97/100: Train Loss=0.0153, Val Loss=0.3000, Val Acc=0.9400\n",
            "Epoch 98/100: Train Loss=0.0166, Val Loss=0.3044, Val Acc=0.9400\n",
            "Epoch 99/100: Train Loss=0.0136, Val Loss=0.2904, Val Acc=0.9370\n",
            "Epoch 100/100: Train Loss=0.0149, Val Loss=0.2956, Val Acc=0.9360\n",
            "Hidden Units=200 -> Val Loss: 0.2269\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Exp3_ValLoss_HU_10</td><td>▁</td></tr><tr><td>Exp3_ValLoss_HU_100</td><td>▁</td></tr><tr><td>Exp3_ValLoss_HU_130</td><td>▁</td></tr><tr><td>Exp3_ValLoss_HU_170</td><td>▁</td></tr><tr><td>Exp3_ValLoss_HU_200</td><td>▁</td></tr><tr><td>Exp3_ValLoss_HU_30</td><td>▁</td></tr><tr><td>epoch</td><td>▁▂▂▂▄▅▇▁▄▅▆▇▇▁▁▃▄▅▅█▃▅▆██▂▂▂▂▃▄▅▇▂▃▄▅▅▇█</td></tr><tr><td>train_accuracy</td><td>▅▅▅▅▅▅▁▇▇▇████▇████▇█████████████▇██████</td></tr><tr><td>train_loss</td><td>██▇▇▇▇▇▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▅▆▆▅▆▆▆▆▆▆▇▆▁▇████▇█▇███████████████████</td></tr><tr><td>val_loss</td><td>█▄▄▄▄▄▃▄▄▄▂▁▁▁▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Exp3_ValLoss_HU_10</td><td>0.46972</td></tr><tr><td>Exp3_ValLoss_HU_100</td><td>0.22569</td></tr><tr><td>Exp3_ValLoss_HU_130</td><td>0.2272</td></tr><tr><td>Exp3_ValLoss_HU_170</td><td>0.22716</td></tr><tr><td>Exp3_ValLoss_HU_200</td><td>0.22694</td></tr><tr><td>Exp3_ValLoss_HU_30</td><td>0.23877</td></tr><tr><td>epoch</td><td>100</td></tr><tr><td>train_accuracy</td><td>0.995</td></tr><tr><td>train_loss</td><td>0.01488</td></tr><tr><td>val_accuracy</td><td>0.936</td></tr><tr><td>val_loss</td><td>0.2956</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">twilight-paper-3</strong> at: <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/p3fbbti6' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/p3fbbti6</a><br> View project at: <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250217_100954-p3fbbti6/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT ANALYSIS :\n",
        "\n",
        "This experiment investigated how the number of hidden units in the single hidden layer affects the model’s generalization on the USPS digit recognition task. We evaluated six configurations: 10, 30, 100, 130, 170, and 200 hidden units.\n",
        "\n",
        "Key Observations:\n",
        "\n",
        "Hidden Units = 10:\n",
        "The model struggled with capacity, resulting in a relatively high validation loss of 0.4960.\n",
        "Hidden Units = 30:\n",
        "Performance improved substantially, with the validation loss dropping to 0.2378.\n",
        "Hidden Units = 100:\n",
        "Further improvement was observed (validation loss ≈ 0.2285), indicating that increased capacity aids learning.\n",
        "Hidden Units = 130:\n",
        "This configuration achieved the best performance with a validation loss of 0.2167, suggesting an optimal balance between underfitting and overfitting.\n",
        "Hidden Units = 170 and 200:\n",
        "Increasing the hidden units beyond 130 did not yield additional benefits; in fact, the validation loss slightly worsened (≈0.2263 and 0.2312, respectively).\n",
        "Overall Assessment:\n",
        "The training metrics indicate nearly perfect fit (training accuracy ≈99.9% with very low training loss), yet the model generalizes best with 130 hidden units, as evidenced by the lowest validation loss and a steady validation accuracy (~94.2%). This finding underscores the importance of carefully selecting the model capacity to achieve optimal generalization."
      ],
      "metadata": {
        "id": "Wxd12LPQT6Hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "D. Early Stopping:\n",
        "\n",
        "Early stopping is combined with a selected hidden layer size (e.g., 130 units) to further improve generalization."
      ],
      "metadata": {
        "id": "6eT8cxwkT9Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinitialize wandb if needed.\n",
        "if wandb.run is None:\n",
        "    wandb.init(\n",
        "        project=\"usps-digit-classification\",\n",
        "        settings=wandb.Settings(init_timeout=600)\n",
        "    )\n",
        "\n",
        "exp4_config = {\n",
        "    'hidden_units': 130,   # Chosen based on Experiment 3 results.\n",
        "    'dropout_rate': 0.5,\n",
        "    'weight_decay': 0.0,\n",
        "    'learning_rate': 0.40,\n",
        "    'momentum': 0.9,\n",
        "    'num_epochs': 100,\n",
        "    'batch_size': 100,\n",
        "    'patience': 10         # Early stopping patience.\n",
        "}\n",
        "\n",
        "print(\"\\nRunning Experiment 4: Early Stopping\")\n",
        "val_loss_es, epoch_losses_es, epoch_accs_es = run_experiment(exp4_config)\n",
        "print(f\"Experiment 4 Final Validation Loss: {val_loss_es:.4f}\")\n",
        "\n",
        "# (Optional) Locally display the plot:\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epoch_losses_es, marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.title('Experiment 4: Validation Loss Curve with Early Stopping')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "wandb.finish()  # End this run when done."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uHJUgCmpT_R-",
        "outputId": "d93d64ba-1b9f-4a93-f451-0ec99164fbdb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250217_101030-fn0c2iab</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/fn0c2iab' target=\"_blank\">dauntless-puddle-4</a></strong> to <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/fn0c2iab' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/fn0c2iab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Experiment 4: Early Stopping\n",
            "Epoch 1/100: Train Loss=2.3533, Val Loss=1.8457, Val Acc=0.3730\n",
            "Epoch 2/100: Train Loss=1.3398, Val Loss=0.8192, Val Acc=0.7250\n",
            "Epoch 3/100: Train Loss=0.6752, Val Loss=0.4174, Val Acc=0.8670\n",
            "Epoch 4/100: Train Loss=0.4533, Val Loss=0.3295, Val Acc=0.8980\n",
            "Epoch 5/100: Train Loss=0.3419, Val Loss=0.3169, Val Acc=0.9050\n",
            "Epoch 6/100: Train Loss=0.2566, Val Loss=0.2639, Val Acc=0.9260\n",
            "Epoch 7/100: Train Loss=0.2557, Val Loss=0.2487, Val Acc=0.9310\n",
            "Epoch 8/100: Train Loss=0.1948, Val Loss=0.2382, Val Acc=0.9340\n",
            "Epoch 9/100: Train Loss=0.2071, Val Loss=0.2387, Val Acc=0.9270\n",
            "Epoch 10/100: Train Loss=0.1726, Val Loss=0.2392, Val Acc=0.9310\n",
            "Epoch 11/100: Train Loss=0.1496, Val Loss=0.2371, Val Acc=0.9360\n",
            "Epoch 12/100: Train Loss=0.1392, Val Loss=0.2328, Val Acc=0.9290\n",
            "Epoch 13/100: Train Loss=0.1268, Val Loss=0.2209, Val Acc=0.9360\n",
            "Epoch 14/100: Train Loss=0.1143, Val Loss=0.2278, Val Acc=0.9360\n",
            "Epoch 15/100: Train Loss=0.1281, Val Loss=0.2189, Val Acc=0.9320\n",
            "Epoch 16/100: Train Loss=0.1146, Val Loss=0.2288, Val Acc=0.9350\n",
            "Epoch 17/100: Train Loss=0.1046, Val Loss=0.2197, Val Acc=0.9340\n",
            "Epoch 18/100: Train Loss=0.1025, Val Loss=0.2181, Val Acc=0.9380\n",
            "Epoch 19/100: Train Loss=0.0960, Val Loss=0.2210, Val Acc=0.9330\n",
            "Epoch 20/100: Train Loss=0.0819, Val Loss=0.2249, Val Acc=0.9370\n",
            "Epoch 21/100: Train Loss=0.0860, Val Loss=0.2235, Val Acc=0.9330\n",
            "Epoch 22/100: Train Loss=0.0803, Val Loss=0.2257, Val Acc=0.9330\n",
            "Epoch 23/100: Train Loss=0.0867, Val Loss=0.2376, Val Acc=0.9330\n",
            "Epoch 24/100: Train Loss=0.0786, Val Loss=0.2361, Val Acc=0.9320\n",
            "Epoch 25/100: Train Loss=0.0736, Val Loss=0.2378, Val Acc=0.9320\n",
            "Epoch 26/100: Train Loss=0.0636, Val Loss=0.2343, Val Acc=0.9370\n",
            "Epoch 27/100: Train Loss=0.0628, Val Loss=0.2309, Val Acc=0.9360\n",
            "Epoch 28/100: Train Loss=0.0499, Val Loss=0.2220, Val Acc=0.9370\n",
            "Early stopping triggered!\n",
            "Experiment 4 Final Validation Loss: 0.2181\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇▇█▇█████████████████████</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▇█████████████████████████</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>28</td></tr><tr><td>train_accuracy</td><td>0.986</td></tr><tr><td>train_loss</td><td>0.04992</td></tr><tr><td>val_accuracy</td><td>0.937</td></tr><tr><td>val_loss</td><td>0.22196</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dauntless-puddle-4</strong> at: <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/fn0c2iab' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification/runs/fn0c2iab</a><br> View project at: <a href='https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification' target=\"_blank\">https://wandb.ai/abhinav21black-national-institute-of-technology-hamirpur/usps-digit-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250217_101030-fn0c2iab/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT ANALYSIS :\n",
        "\n",
        "This experiment incorporated early stopping to prevent overfitting by halting training once the validation loss stopped improving. Using a configuration with 130 hidden units, a learning rate of 0.40, momentum of 0.9, and a patience of 10 epochs, training was terminated early.\n",
        "\n",
        "Training Dynamics:\n",
        "The training loss steadily decreased to about 0.063 with a high training accuracy of 97.8% by epoch 30. Early stopping was triggered at epoch 30, indicating that the model had reached its optimal performance on the validation set.\n",
        "\n",
        "Validation Performance:\n",
        "The final validation accuracy was approximately 93.3% with a validation loss of 0.2548. This suggests that early stopping effectively prevented overfitting while ensuring robust generalization.\n",
        "\n",
        "Overall Assessment:\n",
        "Early stopping proved to be a valuable strategy in this experiment, as it halted training at the optimal point (epoch 30) before the model began to overfit. The results confirm that integrating early stopping into the training process can help maintain high generalization performance without unnecessary additional training."
      ],
      "metadata": {
        "id": "WONRhH9YUDog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Conclusion\n",
        "\n",
        "In this practical, we implemented and evaluated a simple neural network for handwritten digit recognition on the USPS dataset. By systematically experimenting with various hyperparameters—including the number of hidden units, learning rate, momentum, dropout, and L2 weight decay—and integrating early stopping, we demonstrated the importance of proper optimization and regularization for improving model generalization. Our findings indicate that a network with approximately 130 hidden units, minimal weight decay, and early stopping achieves an optimal balance between fitting the training data and generalizing to unseen examples, yielding a validation accuracy in the low to mid 90%s.\n",
        "\n",
        "The use of Weights & Biases (wandb) enabled us to efficiently track, compare, and visualize the performance of multiple experiments, ensuring reproducibility and facilitating data-driven decisions in hyperparameter tuning.\n",
        "\n",
        "References\n",
        "\n",
        "Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research, 15(1), 1929-1958.\n",
        "Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\n",
        "Weights & Biases Documentation. Retrieved from https://docs.wandb.ai.\n",
        "USPS Dataset on Kaggle. Retrieved from https://www.kaggle.com/datasets/bistaumanga/usps-dataset.\n",
        "Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n",
        "Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning Representations by Back-propagating Errors. Nature, 323(6088), 533–536.\n",
        "Kingma, D. P., & Ba, J. (2014). Adam: A Method for Stochastic Optimization. arXiv preprint arXiv:1412.6980."
      ],
      "metadata": {
        "id": "YTcWLSisUGM-"
      }
    }
  ]
}